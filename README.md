# NEN-V: Neuromorphic Energy-based Neural Virtual Model v2.0

![Version](https://img.shields.io/badge/version-2.0.0-blue.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)
![Rust](https://img.shields.io/badge/rust-1.70+-orange.svg)
![Tests](https://img.shields.io/badge/tests-146%20passing-brightgreen.svg)

Uma implementaÃ§Ã£o biologicamente plausÃ­vel de rede neural spiking em Rust, com mecanismos de aprendizado inspirados em neurociÃªncia computacional.

## ğŸ§  VisÃ£o Geral

O NEN-V (Neuromorphic Energy-based Neural Virtual Model) Ã© uma biblioteca Rust que implementa redes neurais spiking com caracterÃ­sticas biologicamente plausÃ­veis. Diferente de redes neurais artificiais tradicionais, o NEN-V simula mecanismos neurofisiolÃ³gicos reais:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           NEN-V v2.0 ARCHITECTURE                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                         COGNITIVE LAYER                                    â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚ â”‚
â”‚  â”‚  â”‚ Working Memory  â”‚  â”‚   Predictive    â”‚  â”‚    Intrinsic            â”‚   â”‚ â”‚
â”‚  â”‚  â”‚ Pool (7Â±2)      â”‚â—„â”€â”¤   Hierarchy     â”‚â—„â”€â”¤    Motivation           â”‚   â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                      â”‚                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                         NEURAL NETWORK                                     â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚ â”‚
â”‚  â”‚  â”‚  Sensory    â”‚â”€â”€â”€â–¶â”‚   Hidden    â”‚â”€â”€â”€â–¶â”‚        Motor               â”‚   â”‚ â”‚
â”‚  â”‚  â”‚  Neurons    â”‚    â”‚   Layers    â”‚    â”‚        Neurons             â”‚   â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚ â”‚
â”‚  â”‚         â”‚                 â”‚                          â”‚                    â”‚ â”‚
â”‚  â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚ â”‚
â”‚  â”‚                           â–¼                                               â”‚ â”‚
â”‚  â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                  â”‚ â”‚
â”‚  â”‚              â”‚     Neuromodulation     â”‚                                  â”‚ â”‚
â”‚  â”‚              â”‚  DA Â· NE Â· ACh Â· 5-HT   â”‚                                  â”‚ â”‚
â”‚  â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                      â”‚                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                         PLASTICITY LAYER                                   â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚  â”‚  â”‚     STDP     â”‚  â”‚ Eligibility  â”‚  â”‚   Homeo-     â”‚  â”‚    Energy    â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  Asymmetric  â”‚â—„â”€â”¤   Traces     â”‚â—„â”€â”¤   stasis     â”‚â—„â”€â”¤   Gating     â”‚  â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Principais CaracterÃ­sticas

| Componente | DescriÃ§Ã£o |
|------------|-----------|
| **STDP AssimÃ©trico** | Spike-Timing-Dependent Plasticity com janelas temporais biologicamente calibradas |
| **Homeostase Multi-escala** | Synaptic scaling, metaplasticidade BCM, threshold adaptativo |
| **Sistema EnergÃ©tico** | Metabolismo neural com glia, reservas energÃ©ticas e energy-gated learning |
| **Working Memory** | Pool de memÃ³ria de trabalho (7Â±2 slots) com dinÃ¢mica de atrator |
| **CodificaÃ§Ã£o Preditiva** | Hierarquia preditiva com Active Inference e Free Energy Principle |
| **Curiosidade IntrÃ­nseca** | ExploraÃ§Ã£o autÃ´noma via ICM (Intrinsic Curiosity Module) |
| **NeuromodulaÃ§Ã£o** | Dopamina, Norepinefrina, Acetilcolina, Serotonina |
| **Eligibility Traces** | Three-factor learning para credit assignment temporal |

## ğŸ“¦ InstalaÃ§Ã£o

### Como DependÃªncia

```toml
[dependencies]
nenv_v2 = { git = "https://github.com/seu-usuario/nenv_v2.git" }
```

### Build Local

```bash
git clone https://github.com/seu-usuario/nenv_v2.git
cd nenv_v2
cargo build --release
```

### Verificar InstalaÃ§Ã£o

```bash
cargo test
# Deve passar todos os 146+ testes
```

## ğŸš€ InÃ­cio RÃ¡pido

### CriaÃ§Ã£o Manual da Rede

```rust
use nenv_v2::prelude::*;

fn main() {
    // Cria rede com 100 neurÃ´nios
    let mut network = Network::new(
        100,                              // NÃºmero de neurÃ´nios
        ConnectivityType::SmallWorld,     // Topologia
        0.2,                              // 20% inibitÃ³rios
        0.15,                             // Threshold de disparo
    );

    network.set_learning_mode(LearningMode::STDP);

    // Loop de simulaÃ§Ã£o
    for step in 0..10000 {
        let inputs = generate_inputs(step);
        network.update(&inputs);

        // Aplica reward externo (ex: do ambiente)
        if step % 100 == 0 {
            network.apply_reward(0.5);
        }

        let stats = network.get_stats();
        if step % 1000 == 0 {
            println!("Step {}: FR={:.1}% Energy={:.1}%",
                     step,
                     stats.firing_rate * 100.0,
                     stats.avg_energy);
        }
    }
}
```

### Usando AutoConfig (Recomendado)

```rust
use nenv_v2::autoconfig::{AutoConfig, TaskSpec, TaskType, RewardDensity};

fn main() {
    // Define tarefa de Reinforcement Learning
    let task = TaskSpec {
        num_sensors: 8,
        num_actuators: 4,
        task_type: TaskType::ReinforcementLearning {
            reward_density: RewardDensity::Sparse,
            temporal_horizon: Some(100),
        },
    };

    // AutoConfig deriva automaticamente 80+ parÃ¢metros
    let config = AutoConfig::from_task(task);
    config.print_report();

    // Cria rede otimizada para a tarefa
    let mut network = config.build_network().expect("ConfiguraÃ§Ã£o vÃ¡lida");
}
```

### Working Memory + Predictive Coding

```rust
use nenv_v2::working_memory::WorkingMemoryPool;
use nenv_v2::predictive::{PredictiveHierarchy, PredictiveConfig};

fn main() {
    // Working Memory (7Â±2 slots como cogniÃ§Ã£o humana)
    let mut wm = WorkingMemoryPool::new(7, 64);

    // Armazena padrÃ£o na memÃ³ria de trabalho
    let pattern = vec![0.5; 64];
    wm.encode(pattern.clone(), 0);

    // Recupera por similaridade
    if let Some(retrieved) = wm.retrieve_by_similarity(&pattern) {
        println!("PadrÃ£o recuperado com sucesso!");
    }

    // Hierarquia Preditiva
    let config = PredictiveConfig::default();
    let mut hierarchy = PredictiveHierarchy::new(vec![64, 32, 16], config);

    // Processa observaÃ§Ã£o
    let observation = vec![0.5; 64];
    let free_energy = hierarchy.process(&observation);
    println!("Free Energy: {:.4}", free_energy);
}
```

### Curiosidade IntrÃ­nseca

```rust
use nenv_v2::intrinsic_motivation::CuriosityModule;

fn main() {
    let mut curiosity = CuriosityModule::new(64, 4);

    let state = vec![0.5; 64];
    let action = vec![1.0, 0.0, 0.0, 0.0];  // One-hot
    let next_state = vec![0.6; 64];

    // Calcula recompensa intrÃ­nseca baseada em surpresa
    let intrinsic_reward = curiosity.compute_intrinsic_reward(
        &state, &action, &next_state
    );

    println!("Recompensa intrÃ­nseca: {:.4}", intrinsic_reward);
    // Maior surpresa = maior reward = mais exploraÃ§Ã£o
}
```

## ğŸ“ Estrutura do Projeto

```
nenv_v2/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ lib.rs                    # Entry point da biblioteca
â”‚   â”œâ”€â”€ nenv.rs                   # NeurÃ´nio individual (NENV)
â”‚   â”œâ”€â”€ dendritoma.rs             # Sistema sinÃ¡ptico
â”‚   â”œâ”€â”€ glia.rs                   # Metabolismo energÃ©tico
â”‚   â”œâ”€â”€ network.rs                # OrquestraÃ§Ã£o de rede
â”‚   â”œâ”€â”€ neuromodulation.rs        # Sistema neuromodulador
â”‚   â”œâ”€â”€ working_memory.rs         # MemÃ³ria de trabalho
â”‚   â”œâ”€â”€ predictive.rs             # CodificaÃ§Ã£o preditiva
â”‚   â”œâ”€â”€ intrinsic_motivation.rs   # Curiosidade intrÃ­nseca
â”‚   â”œâ”€â”€ constants.rs              # Constantes centralizadas
â”‚   â”œâ”€â”€ sparse.rs                 # Matriz esparsa de conectividade
â”‚   â”œâ”€â”€ lru_cache.rs              # Cache LRU para habituaÃ§Ã£o
â”‚   â”œâ”€â”€ plasticity/               # MÃ³dulo de plasticidade
â”‚   â”‚   â”œâ”€â”€ mod.rs
â”‚   â”‚   â”œâ”€â”€ stdp.rs               # STDP implementation
â”‚   â”‚   â”œâ”€â”€ eligibility.rs        # Eligibility traces
â”‚   â”‚   â”œâ”€â”€ short_term.rs         # STP (facilitaÃ§Ã£o/depressÃ£o)
â”‚   â”‚   â””â”€â”€ normalization.rs      # NormalizaÃ§Ã£o sinÃ¡ptica
â”‚   â””â”€â”€ autoconfig/               # Auto-configuraÃ§Ã£o
â”‚       â”œâ”€â”€ mod.rs
â”‚       â”œâ”€â”€ task.rs               # EspecificaÃ§Ã£o de tarefas
â”‚       â”œâ”€â”€ architecture.rs       # DerivaÃ§Ã£o de arquitetura
â”‚       â”œâ”€â”€ params.rs             # DerivaÃ§Ã£o de parÃ¢metros
â”‚       â””â”€â”€ adaptive.rs           # AdaptaÃ§Ã£o online
â”‚
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ basic_network.rs          # Exemplo bÃ¡sico
â”‚   â”œâ”€â”€ rl_agent.rs               # Agente RL
â”‚   â””â”€â”€ curiosity_exploration.rs  # ExploraÃ§Ã£o com curiosidade
â”‚
â”œâ”€â”€ simulations/
â”‚   â””â”€â”€ realtime_environment/     # SimulaÃ§Ã£o interativa
â”‚       â”œâ”€â”€ main.rs               # Grid world navigation
â”‚       â””â”€â”€ README.md
â”‚
â”œâ”€â”€ experiments/
â”‚   â””â”€â”€ hyperparameter_search/    # OtimizaÃ§Ã£o de hiperparÃ¢metros
â”‚       â”œâ”€â”€ main.rs               # CLI principal
â”‚       â”œâ”€â”€ mod.rs                # MÃ³dulo
â”‚       â”œâ”€â”€ param_space.rs        # EspaÃ§o de 45+ parÃ¢metros
â”‚       â”œâ”€â”€ search.rs             # Algoritmos de busca
â”‚       â”œâ”€â”€ evaluation.rs         # Sistema de benchmarks
â”‚       â””â”€â”€ orchestrator.rs       # CoordenaÃ§Ã£o de experimentos
â”‚
â”œâ”€â”€ Cargo.toml
â””â”€â”€ README.md
```

## ğŸ”§ MÃ³dulos Principais

### Core Neural

| MÃ³dulo | Arquivo | DescriÃ§Ã£o |
|--------|---------|-----------|
| **NENV** | `nenv.rs` | NeurÃ´nio individual com integraÃ§Ã£o, disparo e perÃ­odo refratÃ¡rio |
| **Dendritoma** | `dendritoma.rs` | Sistema sinÃ¡ptico com STDP, eligibility traces, STP |
| **Glia** | `glia.rs` | Metabolismo energÃ©tico, reservas, adaptaÃ§Ã£o |
| **Network** | `network.rs` | OrquestraÃ§Ã£o multi-neurÃ´nio com competiÃ§Ã£o e homeostase |
| **Neuromodulation** | `neuromodulation.rs` | DA, NE, ACh, 5-HT com dinÃ¢micas realistas |

### Sistemas Cognitivos

| MÃ³dulo | Arquivo | DescriÃ§Ã£o |
|--------|---------|-----------|
| **Working Memory** | `working_memory.rs` | Pool de memÃ³ria (7Â±2), dinÃ¢mica de atrator, decay |
| **Predictive** | `predictive.rs` | Hierarquia preditiva, Free Energy, Active Inference |
| **Intrinsic Motivation** | `intrinsic_motivation.rs` | ICM, RND, exploraÃ§Ã£o autÃ´noma |

### Plasticidade

| MÃ³dulo | Arquivo | DescriÃ§Ã£o |
|--------|---------|-----------|
| **STDP** | `plasticity/stdp.rs` | AssimÃ©trico, triplet, voltage-dependent |
| **Eligibility** | `plasticity/eligibility.rs` | Three-factor learning, traces temporais |
| **STP** | `plasticity/short_term.rs` | FacilitaÃ§Ã£o e depressÃ£o de curto prazo |
| **Normalization** | `plasticity/normalization.rs` | Synaptic scaling, weight normalization |

### ConfiguraÃ§Ã£o

| MÃ³dulo | Arquivo | DescriÃ§Ã£o |
|--------|---------|-----------|
| **AutoConfig** | `autoconfig/` | DerivaÃ§Ã£o automÃ¡tica de 80+ parÃ¢metros |
| **Constants** | `constants.rs` | Constantes biolÃ³gicas centralizadas |

## ğŸ® SimulaÃ§Ãµes

### Realtime Environment

SimulaÃ§Ã£o completa de navegaÃ§Ã£o em grid world que testa todos os componentes:

```bash
# Modo demonstraÃ§Ã£o (recomendado)
cargo run --release --bin realtime_sim -- --demo

# Modo rÃ¡pido
cargo run --release --bin realtime_sim -- --fast

# Modo benchmark (sem visualizaÃ§Ã£o)
cargo run --release --bin realtime_sim -- --benchmark
```

**CaracterÃ­sticas:**
- Grid 2D com comida, perigos e obstÃ¡culos
- Agente neural com todos os sistemas integrados
- VisualizaÃ§Ã£o em tempo real no terminal
- MÃ©tricas detalhadas (firing rate, energia, neuromoduladores)

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ Â· Â· ğŸ§± Â· Â· Â· ğŸ Â· Â· Â· Â· Â· Â· Â· Â· â•‘
â•‘ Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· ğŸ’€ Â· Â· Â· Â· â•‘
â•‘ Â· Â· Â· Â· Â· ğŸ§± Â· Â· Â· Â· Â· Â· Â· Â· Â· â•‘
â•‘ Â· Â· ğŸ Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· â•‘
â•‘ Â· Â· Â· Â· Â· Â· Â· ğŸ¤– Â· Â· Â· Â· Â· ğŸ§± Â· â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Episode:   15 | Step:    234             â”‚
â”‚ Reward:  +0.990 | Total:  +12.45         â”‚
â”‚ Food:  12 | Danger:   2                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Firing Rate:  8.50% | Energy: 78.3%      â”‚
â”‚ Dopamine:  0.450 | NE:  0.320            â”‚
â”‚ Exploration: 15.2% | WM Slots:  4        â”‚
â”‚ Free Energy:    2.34                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”¬ OtimizaÃ§Ã£o de HiperparÃ¢metros

Sistema completo de busca inteligente com 45+ parÃ¢metros otimizÃ¡veis:

```bash
# Bayesian Optimization (recomendado)
cargo run --release --bin hyperopt -- --strategy bayesian --trials 100

# Random Search rÃ¡pido
cargo run --release --bin hyperopt -- --strategy random --trials 50

# Evolutionary Search
cargo run --release --bin hyperopt -- --strategy evolutionary --trials 200 --population 30

# Teste rÃ¡pido
cargo run --release --bin hyperopt -- --quick

# Ver ajuda
cargo run --release --bin hyperopt -- --help
```

### EstratÃ©gias de Busca

| EstratÃ©gia | DescriÃ§Ã£o | Uso Recomendado |
|------------|-----------|-----------------|
| **Bayesian** | Gaussian Process + UCB | Melhor para poucos trials (<200) |
| **Evolutionary** | Algoritmo genÃ©tico | Bom para espaÃ§os discretos |
| **Random** | Amostragem uniforme | Baseline rÃ¡pido |
| **Grid** | Busca exaustiva | Poucos parÃ¢metros (<5) |

### Categorias de ParÃ¢metros

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PARAMETER SPACE                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ timing         :   6 parameters (STDP windows, traces)      â”‚
â”‚ learning       :   7 parameters (rates, LTP/LTD)            â”‚
â”‚ homeostasis    :   6 parameters (target FR, adaptation)     â”‚
â”‚ energy         :   4 parameters (costs, recovery)           â”‚
â”‚ memory         :   5 parameters (consolidation, tags)       â”‚
â”‚ curiosity      :   3 parameters (scale, habituation)        â”‚
â”‚ network        :   4 parameters (topology, weights)         â”‚
â”‚ working_memory :   3 parameters (capacity, decay)           â”‚
â”‚ predictive     :   2 parameters (inference, learning)       â”‚
â”‚ competition    :   2 parameters (strength, interval)        â”‚
â”‚ sleep          :   2 parameters (replay, noise)             â”‚
â”‚ stp            :   1 parameters (use fraction)              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Total: 45 parameters                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ§ª Testes

```bash
# Todos os testes (146+)
cargo test

# Testes especÃ­ficos por mÃ³dulo
cargo test working_memory
cargo test predictive
cargo test curiosity
cargo test stdp
cargo test homeostasis

# Testes com output detalhado
cargo test -- --nocapture

# Testes do hyperopt
cargo test --bin hyperopt

# Testes da simulaÃ§Ã£o
cargo test --bin realtime_sim
```

## ğŸ“– Exemplos

```bash
# Rede bÃ¡sica com STDP
cargo run --example basic_network

# Agente de Reinforcement Learning
cargo run --example rl_agent

# ExploraÃ§Ã£o autÃ´noma com curiosidade
cargo run --example curiosity_exploration
```

## ğŸ“Š Mecanismos BiolÃ³gicos Implementados

### Plasticidade SinÃ¡ptica âœ…

- [x] **STDP AssimÃ©trico** - tau_plus > tau_minus (Bi & Poo, 1998)
- [x] **iSTDP** - Inhibitory STDP para balanÃ§o E/I
- [x] **Eligibility Traces** - Three-factor learning (Izhikevich, 2007)
- [x] **Short-Term Plasticity** - FacilitaÃ§Ã£o e depressÃ£o
- [x] **Synaptic Tagging** - ConsolidaÃ§Ã£o de memÃ³ria
- [x] **Heterosynaptic Plasticity** - CompetiÃ§Ã£o entre sinapses

### Homeostase âœ…

- [x] **Synaptic Scaling** - NormalizaÃ§Ã£o multiplicativa
- [x] **Intrinsic Plasticity** - Threshold adaptativo
- [x] **Metaplasticidade BCM** - Sliding threshold
- [x] **Controlador PID** - RegulaÃ§Ã£o global de atividade

### Metabolismo âœ…

- [x] **Sistema EnergÃ©tico** - ATP/reservas por neurÃ´nio
- [x] **Energy-Gated Learning** - Plasticidade dependente de energia
- [x] **Glia** - Suporte metabÃ³lico e sinalizaÃ§Ã£o
- [x] **AdaptaÃ§Ã£o MetabÃ³lica** - EficiÃªncia com experiÃªncia

### CogniÃ§Ã£o âœ…

- [x] **Working Memory** - 7Â±2 slots, dinÃ¢mica de atrator
- [x] **Predictive Coding** - Hierarquia com Free Energy
- [x] **Active Inference** - AÃ§Ã£o para reduzir surpresa
- [x] **Curiosidade IntrÃ­nseca** - ICM, RND, exploraÃ§Ã£o

### NeuromodulaÃ§Ã£o âœ…

- [x] **Dopamina** - Reward prediction error
- [x] **Norepinefrina** - Arousal, exploraÃ§Ã£o
- [x] **Acetilcolina** - AtenÃ§Ã£o, encoding
- [x] **Serotonina** - Humor, temporal discounting

## ğŸ”® Roadmap

### v2.1 (Planejado)
- [ ] AtenÃ§Ã£o Top-Down com gating
- [ ] Replay estruturado durante sono
- [ ] MemÃ³ria episÃ³dica com hipocampo simulado
- [ ] IntegraÃ§Ã£o com ambientes OpenAI Gym

### v2.2 (Futuro)
- [ ] Multi-Ã¡rea cortical
- [ ] Oscillations (gamma, theta)
- [ ] Sparse distributed representations
- [ ] GPU acceleration (CUDA/Metal)

## ğŸ“š ReferÃªncias CientÃ­ficas

### Plasticidade
- **STDP**: Bi, G. & Poo, M. (1998). Synaptic modifications in cultured hippocampal neurons.
- **Eligibility Traces**: Izhikevich, E.M. (2007). Solving the distal reward problem.
- **BCM**: Bienenstock, E.L., Cooper, L.N. & Munro, P.W. (1982). Theory for the development of neuron selectivity.

### CodificaÃ§Ã£o Preditiva
- **Predictive Coding**: Rao, R.P. & Ballard, D.H. (1999). Predictive coding in the visual cortex.
- **Free Energy**: Friston, K. (2010). The free-energy principle: a unified brain theory?
- **Active Inference**: Friston, K. et al. (2017). Active inference and epistemic value.

### MotivaÃ§Ã£o IntrÃ­nseca
- **ICM**: Pathak, D. et al. (2017). Curiosity-driven exploration by self-supervised prediction.
- **RND**: Burda, Y. et al. (2018). Exploration by random network distillation.

### Homeostase
- **Synaptic Scaling**: Turrigiano, G.G. (2008). The self-tuning neuron.

### Working Memory
- **Capacity**: Miller, G.A. (1956). The magical number seven, plus or minus two.
- **Attractor Dynamics**: Compte, A. et al. (2000). Synaptic mechanisms and network dynamics.

## ğŸ“„ LicenÃ§a

MIT License - veja [LICENSE](LICENSE) para detalhes.

## ğŸ¤ ContribuiÃ§Ã£o

ContribuiÃ§Ãµes sÃ£o bem-vindas! Por favor:

1. Fork o repositÃ³rio
2. Crie uma branch para sua feature (`git checkout -b feature/nova-feature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add nova feature'`)
4. Push para a branch (`git push origin feature/nova-feature`)
5. Abra um Pull Request

### Guidelines
- Siga o estilo de cÃ³digo existente (rustfmt)
- Adicione testes para novas funcionalidades
- Atualize documentaÃ§Ã£o conforme necessÃ¡rio
- Mantenha compatibilidade com versÃµes anteriores

---

<div align="center">

**Filosofia Central**

*A rede nÃ£o deve ser "programada" para ser inteligente; deve ter os **mecanismos corretos** para que inteligÃªncia **emerja** da interaÃ§Ã£o com o ambiente.*

---

Made with ğŸ§  and â¤ï¸ in Rust

</div>
