# NEN-V: Neuromorphic Energy-based Neural Virtual Model v2.0

![Version](https://img.shields.io/badge/version-2.0.0-blue.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)
![Rust](https://img.shields.io/badge/rust-1.70+-orange.svg)
![Tests](https://img.shields.io/badge/tests-146%20passing-brightgreen.svg)

Uma implementaÃ§Ã£o biologicamente plausÃ­vel de rede neural spiking em Rust, com mecanismos de aprendizado inspirados em neurociÃªncia computacional.

## ğŸ§  VisÃ£o Geral

O NEN-V (Neuromorphic Energy-based Neural Virtual Model) Ã© uma biblioteca Rust que implementa redes neurais spiking com caracterÃ­sticas biologicamente plausÃ­veis. Diferente de redes neurais artificiais tradicionais, o NEN-V simula mecanismos neurofisiolÃ³gicos reais:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           NEN-V v2.0 ARCHITECTURE                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                         COGNITIVE LAYER                                    â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚ â”‚
â”‚  â”‚  â”‚ Working Memory  â”‚  â”‚   Predictive    â”‚  â”‚    Intrinsic            â”‚   â”‚ â”‚
â”‚  â”‚  â”‚ Pool (7Â±2)      â”‚â—„â”€â”¤   Hierarchy     â”‚â—„â”€â”¤    Motivation           â”‚   â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                      â”‚                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                         NEURAL NETWORK                                     â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚ â”‚
â”‚  â”‚  â”‚  Sensory    â”‚â”€â”€â”€â–¶â”‚   Hidden    â”‚â”€â”€â”€â–¶â”‚        Motor               â”‚   â”‚ â”‚
â”‚  â”‚  â”‚  Neurons    â”‚    â”‚   Layers    â”‚    â”‚        Neurons             â”‚   â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚ â”‚
â”‚  â”‚         â”‚                 â”‚                          â”‚                    â”‚ â”‚
â”‚  â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚ â”‚
â”‚  â”‚                           â–¼                                               â”‚ â”‚
â”‚  â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                  â”‚ â”‚
â”‚  â”‚              â”‚     Neuromodulation     â”‚                                  â”‚ â”‚
â”‚  â”‚              â”‚  DA Â· NE Â· ACh Â· 5-HT   â”‚                                  â”‚ â”‚
â”‚  â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                      â”‚                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                         PLASTICITY LAYER                                   â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚  â”‚  â”‚     STDP     â”‚  â”‚ Eligibility  â”‚  â”‚   Homeo-     â”‚  â”‚    Energy    â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  Asymmetric  â”‚â—„â”€â”¤   Traces     â”‚â—„â”€â”¤   stasis     â”‚â—„â”€â”¤   Gating     â”‚  â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Principais CaracterÃ­sticas

| Componente | DescriÃ§Ã£o |
|------------|-----------|
| **STDP AssimÃ©trico** | Spike-Timing-Dependent Plasticity com janelas temporais biologicamente calibradas |
| **Homeostase Multi-escala** | Synaptic scaling, metaplasticidade BCM, threshold adaptativo |
| **Sistema EnergÃ©tico** | Metabolismo neural com glia, reservas energÃ©ticas e energy-gated learning |
| **Working Memory** | Pool de memÃ³ria de trabalho (7Â±2 slots) com dinÃ¢mica de atrator |
| **CodificaÃ§Ã£o Preditiva** | Hierarquia preditiva com Active Inference e Free Energy Principle |
| **Curiosidade IntrÃ­nseca** | ExploraÃ§Ã£o autÃ´noma via ICM (Intrinsic Curiosity Module) |
| **NeuromodulaÃ§Ã£o** | Dopamina, Norepinefrina, Acetilcolina, Serotonina |
| **Eligibility Traces** | Three-factor learning para credit assignment temporal |

## ğŸ“¦ InstalaÃ§Ã£o

### Como DependÃªncia

```toml
[dependencies]
nenv_v2 = { git = "https://github.com/seu-usuario/nenv_v2.git" }
```

### Build Local

```bash
git clone https://github.com/seu-usuario/nenv_v2.git
cd nenv_v2
cargo build --release
```

### Verificar InstalaÃ§Ã£o

```bash
cargo test
# Deve passar todos os 146+ testes
```

## ğŸš€ InÃ­cio RÃ¡pido

### CriaÃ§Ã£o Manual da Rede

```rust
use nenv_v2::prelude::*;

fn main() {
    // Cria rede com 100 neurÃ´nios
    let mut network = Network::new(
        100,                              // NÃºmero de neurÃ´nios
        ConnectivityType::SmallWorld,     // Topologia
        0.2,                              // 20% inibitÃ³rios
        0.15,                             // Threshold de disparo
    );

    network.set_learning_mode(LearningMode::STDP);

    // Loop de simulaÃ§Ã£o
    for step in 0..10000 {
        let inputs = generate_inputs(step);
        network.update(&inputs);

        // Aplica reward externo (ex: do ambiente)
        if step % 100 == 0 {
            network.apply_reward(0.5);
        }

        let stats = network.get_stats();
        if step % 1000 == 0 {
            println!("Step {}: FR={:.1}% Energy={:.1}%",
                     step,
                     stats.firing_rate * 100.0,
                     stats.avg_energy);
        }
    }
}
```

### Usando AutoConfig (Recomendado)

```rust
use nenv_v2::autoconfig::{AutoConfig, TaskSpec, TaskType, RewardDensity};

fn main() {
    // Define tarefa de Reinforcement Learning
    let task = TaskSpec {
        num_sensors: 8,
        num_actuators: 4,
        task_type: TaskType::ReinforcementLearning {
            reward_density: RewardDensity::Sparse,
            temporal_horizon: Some(100),
        },
    };

    // AutoConfig deriva automaticamente 80+ parÃ¢metros
    let config = AutoConfig::from_task(task);
    config.print_report();

    // Cria rede otimizada para a tarefa
    let mut network = config.build_network().expect("ConfiguraÃ§Ã£o vÃ¡lida");
}
```

### Working Memory + Predictive Coding

```rust
use nenv_v2::working_memory::WorkingMemoryPool;
use nenv_v2::predictive::{PredictiveHierarchy, PredictiveConfig};

fn main() {
    // Working Memory (7Â±2 slots como cogniÃ§Ã£o humana)
    let mut wm = WorkingMemoryPool::new(7, 64);

    // Armazena padrÃ£o na memÃ³ria de trabalho
    let pattern = vec![0.5; 64];
    wm.encode(pattern.clone(), 0);

    // Recupera por similaridade
    if let Some(retrieved) = wm.retrieve_by_similarity(&pattern) {
        println!("PadrÃ£o recuperado com sucesso!");
    }

    // Hierarquia Preditiva
    let config = PredictiveConfig::default();
    let mut hierarchy = PredictiveHierarchy::new(vec![64, 32, 16], config);

    // Processa observaÃ§Ã£o
    let observation = vec![0.5; 64];
    let free_energy = hierarchy.process(&observation);
    println!("Free Energy: {:.4}", free_energy);
}
```

### Curiosidade IntrÃ­nseca

```rust
use nenv_v2::intrinsic_motivation::CuriosityModule;

fn main() {
    let mut curiosity = CuriosityModule::new(64, 4);

    let state = vec![0.5; 64];
    let action = vec![1.0, 0.0, 0.0, 0.0];  // One-hot
    let next_state = vec![0.6; 64];

    // Calcula recompensa intrÃ­nseca baseada em surpresa
    let intrinsic_reward = curiosity.compute_intrinsic_reward(
        &state, &action, &next_state
    );

    println!("Recompensa intrÃ­nseca: {:.4}", intrinsic_reward);
    // Maior surpresa = maior reward = mais exploraÃ§Ã£o
}
```

## ğŸ“ Estrutura do Projeto

```
nenv_v2/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ lib.rs                    # Entry point da biblioteca
â”‚   â”œâ”€â”€ nenv.rs                   # NeurÃ´nio individual (NENV)
â”‚   â”œâ”€â”€ dendritoma.rs             # Sistema sinÃ¡ptico
â”‚   â”œâ”€â”€ glia.rs                   # Metabolismo energÃ©tico
â”‚   â”œâ”€â”€ network.rs                # OrquestraÃ§Ã£o de rede
â”‚   â”œâ”€â”€ neuromodulation.rs        # Sistema neuromodulador
â”‚   â”œâ”€â”€ working_memory.rs         # MemÃ³ria de trabalho
â”‚   â”œâ”€â”€ predictive.rs             # CodificaÃ§Ã£o preditiva
â”‚   â”œâ”€â”€ intrinsic_motivation.rs   # Curiosidade intrÃ­nseca
â”‚   â”œâ”€â”€ constants.rs              # Constantes centralizadas
â”‚   â”œâ”€â”€ sparse.rs                 # Matriz esparsa de conectividade
â”‚   â”œâ”€â”€ lru_cache.rs              # Cache LRU para habituaÃ§Ã£o
â”‚   â”œâ”€â”€ plasticity/               # MÃ³dulo de plasticidade
â”‚   â”‚   â”œâ”€â”€ mod.rs
â”‚   â”‚   â”œâ”€â”€ stdp.rs               # STDP implementation
â”‚   â”‚   â”œâ”€â”€ eligibility.rs        # Eligibility traces
â”‚   â”‚   â”œâ”€â”€ short_term.rs         # STP (facilitaÃ§Ã£o/depressÃ£o)
â”‚   â”‚   â””â”€â”€ normalization.rs      # NormalizaÃ§Ã£o sinÃ¡ptica
â”‚   â””â”€â”€ autoconfig/               # Auto-configuraÃ§Ã£o
â”‚       â”œâ”€â”€ mod.rs
â”‚       â”œâ”€â”€ task.rs               # EspecificaÃ§Ã£o de tarefas
â”‚       â”œâ”€â”€ architecture.rs       # DerivaÃ§Ã£o de arquitetura
â”‚       â”œâ”€â”€ params.rs             # DerivaÃ§Ã£o de parÃ¢metros
â”‚       â””â”€â”€ adaptive.rs           # AdaptaÃ§Ã£o online
â”‚
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ basic_network.rs          # Exemplo bÃ¡sico
â”‚   â”œâ”€â”€ rl_agent.rs               # Agente RL
â”‚   â””â”€â”€ curiosity_exploration.rs  # ExploraÃ§Ã£o com curiosidade
â”‚
â”œâ”€â”€ simulations/
â”‚   â””â”€â”€ realtime_environment/     # SimulaÃ§Ã£o interativa
â”‚       â”œâ”€â”€ main.rs               # Grid world navigation
â”‚       â””â”€â”€ README.md
â”‚
â”œâ”€â”€ experiments/
â”‚   â””â”€â”€ hyperparameter_search/    # OtimizaÃ§Ã£o de hiperparÃ¢metros
â”‚       â”œâ”€â”€ main.rs               # CLI principal
â”‚       â”œâ”€â”€ mod.rs                # MÃ³dulo
â”‚       â”œâ”€â”€ param_space.rs        # EspaÃ§o de 45+ parÃ¢metros
â”‚       â”œâ”€â”€ search.rs             # Algoritmos de busca
â”‚       â”œâ”€â”€ evaluation.rs         # Sistema de benchmarks
â”‚       â””â”€â”€ orchestrator.rs       # CoordenaÃ§Ã£o de experimentos
â”‚
â”œâ”€â”€ Cargo.toml
â””â”€â”€ README.md
```

## ğŸ”§ MÃ³dulos Principais

### Core Neural

| MÃ³dulo | Arquivo | DescriÃ§Ã£o |
|--------|---------|-----------|
| **NENV** | `nenv.rs` | NeurÃ´nio individual com integraÃ§Ã£o, disparo e perÃ­odo refratÃ¡rio |
| **Dendritoma** | `dendritoma.rs` | Sistema sinÃ¡ptico com STDP, eligibility traces, STP |
| **Glia** | `glia.rs` | Metabolismo energÃ©tico, reservas, adaptaÃ§Ã£o |
| **Network** | `network.rs` | OrquestraÃ§Ã£o multi-neurÃ´nio com competiÃ§Ã£o e homeostase |
| **Neuromodulation** | `neuromodulation.rs` | DA, NE, ACh, 5-HT com dinÃ¢micas realistas |

### Sistemas Cognitivos

| MÃ³dulo | Arquivo | DescriÃ§Ã£o |
|--------|---------|-----------|
| **Working Memory** | `working_memory.rs` | Pool de memÃ³ria (7Â±2), dinÃ¢mica de atrator, decay |
| **Predictive** | `predictive.rs` | Hierarquia preditiva, Free Energy, Active Inference |
| **Intrinsic Motivation** | `intrinsic_motivation.rs` | ICM, RND, exploraÃ§Ã£o autÃ´noma |

### Plasticidade

| MÃ³dulo | Arquivo | DescriÃ§Ã£o |
|--------|---------|-----------|
| **STDP** | `plasticity/stdp.rs` | AssimÃ©trico, triplet, voltage-dependent |
| **Eligibility** | `plasticity/eligibility.rs` | Three-factor learning, traces temporais |
| **STP** | `plasticity/short_term.rs` | FacilitaÃ§Ã£o e depressÃ£o de curto prazo |
| **Normalization** | `plasticity/normalization.rs` | Synaptic scaling, weight normalization |

### ConfiguraÃ§Ã£o

| MÃ³dulo | Arquivo | DescriÃ§Ã£o |
|--------|---------|-----------|
| **AutoConfig** | `autoconfig/` | DerivaÃ§Ã£o automÃ¡tica de 80+ parÃ¢metros |
| **Constants** | `constants.rs` | Constantes biolÃ³gicas centralizadas |

## ğŸ® SimulaÃ§Ãµes

### Realtime Environment

SimulaÃ§Ã£o completa de navegaÃ§Ã£o em grid world que testa todos os componentes:

```bash
# Modo demonstraÃ§Ã£o (recomendado)
cargo run --release --bin realtime_sim -- --demo

# Modo rÃ¡pido
cargo run --release --bin realtime_sim -- --fast

# Modo benchmark (sem visualizaÃ§Ã£o)
cargo run --release --bin realtime_sim -- --benchmark
```

**CaracterÃ­sticas:**
- Grid 2D com comida, perigos e obstÃ¡culos
- Agente neural com todos os sistemas integrados
- VisualizaÃ§Ã£o em tempo real no terminal
- MÃ©tricas detalhadas (firing rate, energia, neuromoduladores)

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ Â· Â· ğŸ§± Â· Â· Â· ğŸ Â· Â· Â· Â· Â· Â· Â· Â· â•‘
â•‘ Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· ğŸ’€ Â· Â· Â· Â· â•‘
â•‘ Â· Â· Â· Â· Â· ğŸ§± Â· Â· Â· Â· Â· Â· Â· Â· Â· â•‘
â•‘ Â· Â· ğŸ Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· Â· â•‘
â•‘ Â· Â· Â· Â· Â· Â· Â· ğŸ¤– Â· Â· Â· Â· Â· ğŸ§± Â· â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Episode:   15 | Step:    234             â”‚
â”‚ Reward:  +0.990 | Total:  +12.45         â”‚
â”‚ Food:  12 | Danger:   2                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Firing Rate:  8.50% | Energy: 78.3%      â”‚
â”‚ Dopamine:  0.450 | NE:  0.320            â”‚
â”‚ Exploration: 15.2% | WM Slots:  4        â”‚
â”‚ Free Energy:    2.34                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## âš™ï¸ Arquitetura de ParÃ¢metros

O NEN-V utiliza uma arquitetura de configuraÃ§Ã£o em **3 nÃ­veis hierÃ¡rquicos**, permitindo desde uso simples atÃ© otimizaÃ§Ã£o avanÃ§ada:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        HIERARQUIA DE CONFIGURAÃ‡ÃƒO                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  NÃVEL 3: HYPERPARAMETER SEARCH (experiments/hyperparameter_search/)       â”‚ â”‚
â”‚  â”‚  â”œâ”€â”€ 45+ parÃ¢metros otimizÃ¡veis via Bayesian/Evolutionary/Random search   â”‚ â”‚
â”‚  â”‚  â”œâ”€â”€ Busca automatizada com early stopping                                 â”‚ â”‚
â”‚  â”‚  â””â”€â”€ Benchmarks integrados para avaliaÃ§Ã£o                                  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                      â”‚                                           â”‚
â”‚                                      â–¼                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  NÃVEL 2: AUTOCONFIG (src/autoconfig/)                                     â”‚ â”‚
â”‚  â”‚  â”œâ”€â”€ Deriva automaticamente 80+ parÃ¢metros a partir de TaskSpec           â”‚ â”‚
â”‚  â”‚  â”œâ”€â”€ Otimizado via grid-search para casos comuns                          â”‚ â”‚
â”‚  â”‚  â””â”€â”€ Recomendado para maioria dos usos                                    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                      â”‚                                           â”‚
â”‚                                      â–¼                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  NÃVEL 1: HARDCODE (ProteÃ§Ã£o contra instabilidade)                        â”‚ â”‚
â”‚  â”‚  â”œâ”€â”€ Pisos mÃ­nimos de pesos e recursos (evita morte sinÃ¡ptica)            â”‚ â”‚
â”‚  â”‚  â”œâ”€â”€ Limites de mudanÃ§a por update (evita runaway LTP/LTD)                â”‚ â”‚
â”‚  â”‚  â””â”€â”€ Mecanismos de resgate (recupera de estados degenerados)              â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### NÃ­vel 1: Constantes de ProteÃ§Ã£o (Hardcoded)

Valores de seguranÃ§a que **nÃ£o devem ser alterados** sem profundo entendimento do sistema:

| Constante | Valor | LocalizaÃ§Ã£o | PropÃ³sito |
|-----------|-------|-------------|-----------|
| `min_weight` | 0.02 | `dendritoma.rs` | Piso de peso sinÃ¡ptico - evita morte sinÃ¡ptica |
| `min_resources` | 0.2 | `dendritoma.rs` | Piso de recursos STP - garante transmissÃ£o basal |
| `max_change_per_update` | 0.05 | `dendritoma.rs` | Limite de mudanÃ§a STDP - evita runaway LTP/LTD |
| `rescue_factor` | 0.1 | `dendritoma.rs` | Fator de resgate - protege pesos durante inatividade |
| `min_threshold` (dead) | 0.001 | `nenv.rs` | Piso absoluto de threshold quando neurÃ´nio estÃ¡ morto |

### NÃ­vel 2: AutoConfig (DerivaÃ§Ã£o AutomÃ¡tica)

O sistema AutoConfig deriva **80+ parÃ¢metros** automaticamente a partir de uma especificaÃ§Ã£o mÃ­nima:

```rust
let task = TaskSpec {
    num_sensors: 8,
    num_actuators: 4,
    task_type: TaskType::ReinforcementLearning {
        reward_density: RewardDensity::Sparse,
        temporal_horizon: Some(100),
    },
};

let config = AutoConfig::from_task(task);
let network = config.build_network().expect("OK");
```

**ParÃ¢metros Derivados por Categoria:**

| Categoria | ParÃ¢metros | Derivados de |
|-----------|------------|--------------|
| **Arquitetura** | total_neurons, hidden_layers, connectivity | num_sensors, num_actuators |
| **Threshold** | initial_threshold (0.20) | connectivity, task_type |
| **Pesos** | excitatory (0.5), inhibitory (1.6) | inhibitory_ratio, target_FR |
| **STDP** | tau_plus (12.8), tau_minus (4.8), a_plus, a_minus | connectivity, learning_rate |
| **Homeostase** | target_firing_rate (0.22), homeo_eta (0.16) | total_neurons |
| **Eligibility** | trace_tau, trace_increment, enabled | reward_density, temporal_horizon |
| **STP** | recovery_tau, use_fraction | temporal_horizon |
| **Curiosidade** | scale, habituation_rate | reward_density |

### NÃ­vel 3: Hyperparameter Search (OtimizaÃ§Ã£o AvanÃ§ada)

Para maximizar desempenho em tarefas especÃ­ficas, use o sistema de otimizaÃ§Ã£o:

**ParÃ¢metros OtimizÃ¡veis por ImportÃ¢ncia:**

| ImportÃ¢ncia | ParÃ¢metro | Range | DescriÃ§Ã£o |
|-------------|-----------|-------|-----------|
| **0.95** | `learning.base_learning_rate` | [0.001, 0.1] | Taxa base de aprendizado |
| **0.90** | `timing.stdp_window` | [10, 100] | Janela temporal STDP |
| **0.90** | `homeostasis.target_firing_rate` | [0.03, 0.25] | Taxa de disparo alvo |
| **0.90** | `learning.stdp_a_plus` | [0.001, 0.1] | Amplitude LTP |
| **0.90** | `learning.stdp_a_minus` | [0.001, 0.1] | Amplitude LTD |
| **0.85** | `timing.stdp_tau_plus` | [10, 100] | Constante tempo LTP |
| **0.85** | `timing.stdp_tau_minus` | [5, 50] | Constante tempo LTD |
| **0.85** | `homeostasis.homeo_eta` | [0.01, 0.5] | Taxa ajuste homeostÃ¡tico |
| **0.85** | `network.adaptive_threshold_multiplier` | [0.5, 5.0] | ForÃ§a do sparse coding |
| **0.80** | `network.inhibitory_ratio` | [0.1, 0.4] | RazÃ£o E/I |

### Workflow Recomendado

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Comece com AutoConfig para sua tarefa                        â”‚
â”‚    â””â”€â”€ config = AutoConfig::from_task(task)                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2. Teste com deep_diagnostic para verificar estabilidade        â”‚
â”‚    â””â”€â”€ cargo run --release --bin deep_diagnostic                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 3. Se necessÃ¡rio, rode hyperopt para otimizar                   â”‚
â”‚    â””â”€â”€ cargo run --release --bin hyperopt -- --trials 100       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 4. Atualize derivation.rs com melhores parÃ¢metros encontrados   â”‚
â”‚    â””â”€â”€ src/autoconfig/derivation.rs                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 5. Ou faÃ§a override manual apÃ³s build_network()                 â”‚
â”‚    â””â”€â”€ neuron.homeo_eta = 0.25;                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”¬ OtimizaÃ§Ã£o de HiperparÃ¢metros

Sistema completo de busca inteligente com 45+ parÃ¢metros otimizÃ¡veis:

```bash
# Bayesian Optimization (recomendado)
cargo run --release --bin hyperopt -- --strategy bayesian --trials 100

# Random Search rÃ¡pido
cargo run --release --bin hyperopt -- --strategy random --trials 50

# Evolutionary Search
cargo run --release --bin hyperopt -- --strategy evolutionary --trials 200 --population 30

# Teste rÃ¡pido
cargo run --release --bin hyperopt -- --quick

# Ver ajuda
cargo run --release --bin hyperopt -- --help
```

### EstratÃ©gias de Busca

| EstratÃ©gia | DescriÃ§Ã£o | Uso Recomendado |
|------------|-----------|-----------------|
| **Bayesian** | Gaussian Process + UCB | Melhor para poucos trials (<200) |
| **Evolutionary** | Algoritmo genÃ©tico | Bom para espaÃ§os discretos |
| **Random** | Amostragem uniforme | Baseline rÃ¡pido |
| **Grid** | Busca exaustiva | Poucos parÃ¢metros (<5) |

### Categorias de ParÃ¢metros

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PARAMETER SPACE                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ timing         :   6 parameters (STDP windows, traces)      â”‚
â”‚ learning       :   7 parameters (rates, LTP/LTD)            â”‚
â”‚ homeostasis    :   6 parameters (target FR, adaptation)     â”‚
â”‚ energy         :   4 parameters (costs, recovery)           â”‚
â”‚ memory         :   5 parameters (consolidation, tags)       â”‚
â”‚ curiosity      :   3 parameters (scale, habituation)        â”‚
â”‚ network        :   4 parameters (topology, weights)         â”‚
â”‚ working_memory :   3 parameters (capacity, decay)           â”‚
â”‚ predictive     :   2 parameters (inference, learning)       â”‚
â”‚ competition    :   2 parameters (strength, interval)        â”‚
â”‚ sleep          :   2 parameters (replay, noise)             â”‚
â”‚ stp            :   1 parameters (use fraction)              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Total: 45 parameters                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ” Ferramentas de DiagnÃ³stico

O NEN-V inclui ferramentas para monitorar e diagnosticar o comportamento da rede:

### Deep Diagnostic

AnÃ¡lise completa do estado interno da rede ao longo do tempo:

```bash
cargo run --release --bin deep_diagnostic
```

**Output:**

```
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    DEEP DIAGNOSTIC - NEN-V NETWORK ANALYSIS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“Š SNAPSHOT @ Step 10000
â”œâ”€â”€ ğŸ”¥ ATIVIDADE
â”‚   â”œâ”€â”€ Firing Rate: 8.50%
â”‚   â”œâ”€â”€ Neurons Firing: 17/200
â”‚   â””â”€â”€ Recent Activity: 0.085
â”‚
â”œâ”€â”€ âš¡ THRESHOLD
â”‚   â”œâ”€â”€ Mean: 0.1523  Std: 0.0234
â”‚   â””â”€â”€ Range: [0.0892, 0.2341]
â”‚
â”œâ”€â”€ ğŸ”— SINAPSES
â”‚   â”œâ”€â”€ Weight Mean: 0.4521  Std: 0.1234
â”‚   â”œâ”€â”€ Dead Synapses: 0 (0.00%)
â”‚   â””â”€â”€ Saturated: 12 (0.60%)
â”‚
â”œâ”€â”€ ğŸ”‹ ENERGIA
â”‚   â”œâ”€â”€ Mean: 87.3%  Min: 45.2%
â”‚   â””â”€â”€ Low Energy Neurons: 3
â”‚
â””â”€â”€ ğŸ“ˆ RECURSOS STP
    â”œâ”€â”€ Mean: 0.7823
    â””â”€â”€ Depleted (<0.3): 5

âš ï¸  DIAGNÃ“STICO DE BLOQUEIO
â”œâ”€â”€ By Threshold: 42 (21.0%)
â”œâ”€â”€ By Refractory: 18 (9.0%)
â”œâ”€â”€ By Energy: 3 (1.5%)
â””â”€â”€ Total Blocked: 63 (31.5%)
```

### Adaptive Learning Simulation

Testa a capacidade de aprendizado adaptativo:

```bash
cargo run --release --bin adaptive_learning
```

### Test Fire (Exemplo de DiagnÃ³stico)

Teste rÃ¡pido de disparo e auto-regulaÃ§Ã£o:

```bash
cargo run --release --example test_fire
```

**Output:**

```
=== TESTE DE AUTO-REGULAÃ‡ÃƒO ===
Target FR: 0.2236

=== SIMULACAO ===
Step  5000: avg_FR=0.0823 | threshold=0.0412 | weight=0.4521
Step 10000: avg_FR=0.0912 | threshold=0.0389 | weight=0.4623
Step 15000: avg_FR=0.1234 | threshold=0.0356 | weight=0.4712
...

=== RESULTADO FINAL ===
FR Geral: 0.1523
Target:   0.2236
Erro:     31.89%

Teste disparo: potencial=0.2341 vs threshold=0.0892 â†’ DISPARA
```

### MÃ©tricas Monitoradas

| Categoria | MÃ©tricas | Significado |
|-----------|----------|-------------|
| **Atividade** | firing_rate, recent_activity | SaÃºde geral da rede |
| **Threshold** | mean, std, range | AdaptaÃ§Ã£o homeostÃ¡tica |
| **Sinapses** | weights, dead_count, saturated | Estabilidade plÃ¡stica |
| **Energia** | avg_energy, low_count | Capacidade metabÃ³lica |
| **STP** | resources, depleted_count | EficÃ¡cia de transmissÃ£o |
| **Bloqueio** | by_threshold, by_refractory, by_energy | DiagnÃ³stico de silenciamento |

### Sinais de Problemas e SoluÃ§Ãµes

| Sintoma | PossÃ­vel Causa | SoluÃ§Ã£o |
|---------|----------------|---------|
| FR = 0% | Pesos muito baixos | Verificar `min_weight`, aumentar `homeo_eta` |
| FR > 50% | Threshold muito baixo | Aumentar `target_firing_rate` |
| Dead synapses > 5% | Weight decay agressivo | Reduzir `weight_decay` |
| Saturated > 20% | LTP runaway | Aumentar `max_change_per_update` |
| Low energy > 30% | Atividade excessiva | Aumentar `energy_recovery_rate` |
| Depleted STP > 30% | Input muito frequente | Aumentar `stp_recovery_tau` |

---

## ğŸ§ª Testes

```bash
# Todos os testes (146+)
cargo test

# Testes especÃ­ficos por mÃ³dulo
cargo test working_memory
cargo test predictive
cargo test curiosity
cargo test stdp
cargo test homeostasis

# Testes com output detalhado
cargo test -- --nocapture

# Testes do hyperopt
cargo test --bin hyperopt

# Testes da simulaÃ§Ã£o
cargo test --bin realtime_sim
```

## ğŸ“– Exemplos

```bash
# Rede bÃ¡sica com STDP
cargo run --example basic_network

# Agente de Reinforcement Learning
cargo run --example rl_agent

# ExploraÃ§Ã£o autÃ´noma com curiosidade
cargo run --example curiosity_exploration
```

## ğŸ“Š Mecanismos BiolÃ³gicos Implementados

### Plasticidade SinÃ¡ptica âœ…

- [x] **STDP AssimÃ©trico** - tau_plus > tau_minus (Bi & Poo, 1998)
- [x] **iSTDP** - Inhibitory STDP para balanÃ§o E/I
- [x] **Eligibility Traces** - Three-factor learning (Izhikevich, 2007)
- [x] **Short-Term Plasticity** - FacilitaÃ§Ã£o e depressÃ£o
- [x] **Synaptic Tagging** - ConsolidaÃ§Ã£o de memÃ³ria
- [x] **Heterosynaptic Plasticity** - CompetiÃ§Ã£o entre sinapses

### Homeostase âœ…

- [x] **Synaptic Scaling** - NormalizaÃ§Ã£o multiplicativa
- [x] **Intrinsic Plasticity** - Threshold adaptativo
- [x] **Metaplasticidade BCM** - Sliding threshold
- [x] **Controlador PID** - RegulaÃ§Ã£o global de atividade

### Metabolismo âœ…

- [x] **Sistema EnergÃ©tico** - ATP/reservas por neurÃ´nio
- [x] **Energy-Gated Learning** - Plasticidade dependente de energia
- [x] **Glia** - Suporte metabÃ³lico e sinalizaÃ§Ã£o
- [x] **AdaptaÃ§Ã£o MetabÃ³lica** - EficiÃªncia com experiÃªncia

### CogniÃ§Ã£o âœ…

- [x] **Working Memory** - 7Â±2 slots, dinÃ¢mica de atrator
- [x] **Predictive Coding** - Hierarquia com Free Energy
- [x] **Active Inference** - AÃ§Ã£o para reduzir surpresa
- [x] **Curiosidade IntrÃ­nseca** - ICM, RND, exploraÃ§Ã£o

### NeuromodulaÃ§Ã£o âœ…

- [x] **Dopamina** - Reward prediction error
- [x] **Norepinefrina** - Arousal, exploraÃ§Ã£o
- [x] **Acetilcolina** - AtenÃ§Ã£o, encoding
- [x] **Serotonina** - Humor, temporal discounting

## ğŸ”® Roadmap

### v2.1 (Planejado)
- [ ] AtenÃ§Ã£o Top-Down com gating
- [ ] Replay estruturado durante sono
- [ ] MemÃ³ria episÃ³dica com hipocampo simulado
- [ ] IntegraÃ§Ã£o com ambientes OpenAI Gym

### v2.2 (Futuro)
- [ ] Multi-Ã¡rea cortical
- [ ] Oscillations (gamma, theta)
- [ ] Sparse distributed representations
- [ ] GPU acceleration (CUDA/Metal)

## ğŸ“š ReferÃªncias CientÃ­ficas

### Plasticidade
- **STDP**: Bi, G. & Poo, M. (1998). Synaptic modifications in cultured hippocampal neurons.
- **Eligibility Traces**: Izhikevich, E.M. (2007). Solving the distal reward problem.
- **BCM**: Bienenstock, E.L., Cooper, L.N. & Munro, P.W. (1982). Theory for the development of neuron selectivity.

### CodificaÃ§Ã£o Preditiva
- **Predictive Coding**: Rao, R.P. & Ballard, D.H. (1999). Predictive coding in the visual cortex.
- **Free Energy**: Friston, K. (2010). The free-energy principle: a unified brain theory?
- **Active Inference**: Friston, K. et al. (2017). Active inference and epistemic value.

### MotivaÃ§Ã£o IntrÃ­nseca
- **ICM**: Pathak, D. et al. (2017). Curiosity-driven exploration by self-supervised prediction.
- **RND**: Burda, Y. et al. (2018). Exploration by random network distillation.

### Homeostase
- **Synaptic Scaling**: Turrigiano, G.G. (2008). The self-tuning neuron.

### Working Memory
- **Capacity**: Miller, G.A. (1956). The magical number seven, plus or minus two.
- **Attractor Dynamics**: Compte, A. et al. (2000). Synaptic mechanisms and network dynamics.

## ğŸ“„ LicenÃ§a

MIT License - veja [LICENSE](LICENSE) para detalhes.

## ğŸ¤ ContribuiÃ§Ã£o

ContribuiÃ§Ãµes sÃ£o bem-vindas! Por favor:

1. Fork o repositÃ³rio
2. Crie uma branch para sua feature (`git checkout -b feature/nova-feature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add nova feature'`)
4. Push para a branch (`git push origin feature/nova-feature`)
5. Abra um Pull Request

### Guidelines
- Siga o estilo de cÃ³digo existente (rustfmt)
- Adicione testes para novas funcionalidades
- Atualize documentaÃ§Ã£o conforme necessÃ¡rio
- Mantenha compatibilidade com versÃµes anteriores

---

<div align="center">

**Filosofia Central**

*A rede nÃ£o deve ser "programada" para ser inteligente; deve ter os **mecanismos corretos** para que inteligÃªncia **emerja** da interaÃ§Ã£o com o ambiente.*

---

Made with ğŸ§  and â¤ï¸ in Rust

</div>
