/// M√≥dulo que implementa o neur√≥nio NENV (Neur√≥nio-Entrada-N√∫cleo-Vasos)
///
/// O NENV √© a unidade central da arquitetura, integrando o Dendritoma (entrada),
/// a Glia (modula√ß√£o metab√≥lica) e mem√≥ria contextual.

use crate::dendritoma::Dendritoma;
use crate::glia::Glia;
use std::collections::VecDeque;

/// Tipo de neur√≥nio: Excitat√≥rio ou Inibit√≥rio
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum NeuronType {
    /// Neur√≥nios excitat√≥rios emitem sinais positivos (+1.0)
    Excitatory,
    /// Neur√≥nios inibit√≥rios emitem sinais negativos (-1.0)
    Inhibitory,
}

/// Origem do spike: usado para STDP gated (3-factor STDP)
///
/// Distingue entre spikes genu√≠nos (threshold-crossing) e spikes
/// for√ßados por input externo ou gerados por feedback recorrente.
/// Isso previne que loops de feedback sejam refor√ßados por STDP.
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum SpikeOrigin {
    /// Spike end√≥geno: gerado naturalmente ao ultrapassar threshold
    /// Estes s√£o spikes "leg√≠timos" que devem participar de STDP
    Endogenous,

    /// Spike ex√≥geno: for√ßado por input externo (est√≠mulo experimental)
    /// Usados para treinar padr√µes espec√≠ficos via STDP
    Exogenous,

    /// Spike de feedback: causado por recorr√™ncia na rede
    /// N√ÉO devem participar de STDP para evitar runaway LTP
    Feedback,

    /// Nenhum spike ocorreu
    None,
}

/// Estrutura principal do neur√≥nio NENV
#[derive(Debug, Clone)]
pub struct NENV {
    /// Identificador √∫nico do neur√≥nio
    pub id: usize,

    /// Tipo do neur√≥nio (excitat√≥rio ou inibit√≥rio)
    pub neuron_type: NeuronType,

    /// Componente de entrada e aprendizado sin√°ptico
    pub dendritoma: Dendritoma,

    /// Componente de modula√ß√£o metab√≥lica
    pub glia: Glia,

    /// Tra√ßo de mem√≥ria contextual (m√©dia m√≥vel exponencial dos inputs)
    pub memory_trace: Vec<f64>,

    /// Passo de tempo do √∫ltimo disparo
    pub last_fire_time: i64,

    /// Hist√≥rico de tempos de spikes recentes (para STDP)
    /// Mant√©m apenas os √∫ltimos N spikes dentro da janela temporal relevante
    spike_history: VecDeque<i64>,

    /// Limiar de disparo
    pub threshold: f64,

    /// Limiar de disparo inicial (refer√™ncia para clamps adaptativos)
    base_threshold: f64,

    /// Contador de overshoot para modular piso din√¢mico
    overshoot_count: f64,

    /// Estado de disparo atual
    pub is_firing: bool,

    /// Origem do √∫ltimo spike (para STDP gated/3-factor)
    /// Permite distinguir spikes end√≥genos, ex√≥genos e de feedback
    pub spike_origin: SpikeOrigin,

    /// Sinal de sa√≠da (+1.0 para excitat√≥rio, -1.0 para inibit√≥rio, 0.0 se n√£o disparou)
    pub output_signal: f64,

    // Par√¢metros de din√¢mica
    refractory_period: i64,
    memory_alpha: f64,

    /// Taxa de disparo recente (m√©dia m√≥vel exponencial)
    /// Usada para guiar o replay durante o sono
    pub recent_firing_rate: f64,

    /// Taxa de disparo salva antes de entrar no sono
    /// Preserva a atividade durante vig√≠lia para replay mais preciso
    pub saved_awake_activity: f64,

    // Par√¢metros de plasticidade homeost√°tica
    /// Taxa de disparo alvo para homeostase (default: 0.1 = 10% de atividade)
    pub target_firing_rate: f64,

    /// Taxa de ajuste homeost√°tico (default: 0.01)
    pub homeo_eta: f64,

    /// Intervalo entre aplica√ß√µes de homeostase (em passos)
    pub homeo_interval: i64,

    /// √öltimo passo em que homeostase foi aplicada
    last_homeo_update: i64,

    /// Propor√ß√£o do esfor√ßo homeost√°tico em ajuste de pesos (0.0-1.0)
    /// Default: 0.7 (70% em pesos, 30% em threshold)
    pub homeo_weight_ratio: f64,

    /// Propor√ß√£o do esfor√ßo homeost√°tico em ajuste de threshold (0.0-1.0)
    /// Default: 0.3 (30% threshold, 70% pesos)
    /// Nota: weight_ratio + threshold_ratio devem somar 1.0
    pub homeo_threshold_ratio: f64,

    // Par√¢metros de metaplasticidade BCM
    /// Limiar metapl√°stico din√¢mico (Œ∏_M na teoria BCM)
    /// Ajusta-se baseado na atividade quadr√°tica m√©dia
    pub meta_threshold: f64,

    /// Taxa de atualiza√ß√£o do meta_threshold (alpha para EMA)
    pub meta_alpha: f64,
}

impl NENV {
    /// Cria um novo neur√≥nio NENV
    ///
    /// # Argumentos
    /// * `id` - Identificador √∫nico
    /// * `num_inputs` - N√∫mero de conex√µes de entrada
    /// * `initial_threshold` - Limiar de disparo inicial
    /// * `neuron_type` - Tipo do neur√≥nio (excitat√≥rio ou inibit√≥rio)
    pub fn new(
        id: usize,
        num_inputs: usize,
        initial_threshold: f64,
        neuron_type: NeuronType,
    ) -> Self {
        Self {
            id,
            neuron_type,
            dendritoma: Dendritoma::new(num_inputs),
            glia: Glia::new(),
            memory_trace: vec![0.0; num_inputs],
            last_fire_time: -1,
            spike_history: VecDeque::with_capacity(10),
            threshold: initial_threshold,
            base_threshold: initial_threshold,
            overshoot_count: 0.0,
            is_firing: false,
            spike_origin: SpikeOrigin::None,
            output_signal: 0.0,
            // RESTAURADO: Per√≠odo refrat√°rio biol√≥gico (5ms)
            refractory_period: 5,
            memory_alpha: 0.02,
            recent_firing_rate: 0.0,
            saved_awake_activity: 0.0,
            target_firing_rate: 0.15,  // Ser√° sobrescrito pelo AutoConfig
            // Par√¢metros homeost√°ticos ajustados via grid-search (W65T35_eta3.3x_int0.858x)
            homeo_eta: 0.1627,     // 0.05 * 3.253 (grid)
            homeo_interval: 9,     // 10 * 0.858 (grid, arredondado)
            last_homeo_update: -1,
            homeo_weight_ratio: 0.650,    // Grid-search
            homeo_threshold_ratio: 0.350, // Grid-search
            meta_threshold: 0.12,  // OTIMIZADO: BCM threshold
            meta_alpha: 0.005,     // OTIMIZADO: BCM learning rate
        }
    }

    /// Cria um neur√≥nio excitat√≥rio
    pub fn excitatory(id: usize, num_inputs: usize, initial_threshold: f64) -> Self {
        Self::new(id, num_inputs, initial_threshold, NeuronType::Excitatory)
    }

    /// Cria um neur√≥nio inibit√≥rio
    pub fn inhibitory(id: usize, num_inputs: usize, initial_threshold: f64) -> Self {
        Self::new(id, num_inputs, initial_threshold, NeuronType::Inhibitory)
    }

    /// Decide se o neur√≥nio deve disparar baseado no potencial modulado
    ///
    /// # Argumentos
    /// * `modulated_potential` - Potencial ap√≥s modula√ß√£o glial
    /// * `current_time` - Passo de tempo atual da simula√ß√£o
    /// * `has_external_input` - True se h√° input externo direto (para STDP gated)
    pub fn decide_to_fire(&mut self, modulated_potential: f64, current_time: i64, has_external_input: bool) {
        // Verifica per√≠odo refrat√°rio
        // Neur√¥nio nunca disparado (last_fire_time = -1) n√£o est√° em refrat√°rio
        let is_in_refractory = if self.last_fire_time < 0 {
            false
        } else {
            (current_time - self.last_fire_time) < self.refractory_period
        };

        // Reset do estado de disparo
        self.is_firing = false;
        self.spike_origin = SpikeOrigin::None;
        self.output_signal = 0.0;

        // SPARSE CODING: Adaptive threshold aumenta com firing rate
        // Se neur√¥nio dispara muito ‚Üí threshold sobe ‚Üí mais dif√≠cil disparar
        let adaptive_threshold = self.threshold * (1.0 + self.recent_firing_rate * 3.0);

        // HARD ENERGY GATING: S√≥ dispara se tem energia m√≠nima
        // (energy_level j√° foi reduzido por glia.modulate)
        let has_energy = self.glia.energy > 5.0;  // Reserva m√≠nima

        // Dispara se: potencial > adaptive_threshold E n√£o refrat√°rio E tem energia
        if modulated_potential > adaptive_threshold && !is_in_refractory && has_energy {
            self.is_firing = true;
            self.last_fire_time = current_time;

            // Overshoot tracking: incrementa se muito acima do target recente
            if self.recent_firing_rate > self.target_firing_rate * 2.0 {
                self.overshoot_count = (self.overshoot_count + 1.0).min(100.0);
            }

            // Determina a origem do spike (STDP gated / 3-factor)
            // Regra: Se h√° input externo direto ‚Üí Exogenous
            //        Se n√£o ‚Üí pode ser Endogenous (genu√≠no) ou Feedback (recorrente)
            //        Para distinguir Endogenous de Feedback, verificamos se o potencial
            //        √© muito maior que o threshold (indica feedback intenso)
            if has_external_input {
                self.spike_origin = SpikeOrigin::Exogenous;
            } else {
                // Heur√≠stica: potencial >> threshold sugere feedback recorrente
                // Se potencial √© apenas ligeiramente acima do threshold ‚Üí Endogenous
                let excess = modulated_potential - self.threshold;
                if excess > self.threshold * 2.0 {
                    // Potencial muito alto ‚Üí provavelmente feedback recorrente
                    self.spike_origin = SpikeOrigin::Feedback;
                } else {
                    // Potencial moderado ‚Üí disparo genu√≠no/end√≥geno
                    self.spike_origin = SpikeOrigin::Endogenous;
                }
            }

            // Registra spike no hist√≥rico para STDP
            self.spike_history.push_back(current_time);

            // Limita hist√≥rico aos √∫ltimos 10 spikes
            if self.spike_history.len() > 10 {
                self.spike_history.pop_front();
            }

            // O sinal de sa√≠da depende do tipo de neur√≥nio
            self.output_signal = match self.neuron_type {
                NeuronType::Excitatory => 1.0,
                NeuronType::Inhibitory => -1.0,
            };
        }
    }

    /// Atualiza a mem√≥ria contextual do neur√≥nio
    ///
    /// Implementa uma m√©dia m√≥vel exponencial dos padr√µes de entrada,
    /// permitindo que o neur√≥nio "lembre" inputs recentes.
    ///
    /// # Argumentos
    /// * `inputs` - Vetor de sinais de entrada atual
    pub fn update_memory(&mut self, inputs: &[f64]) {
        assert_eq!(
            inputs.len(),
            self.memory_trace.len(),
            "N√∫mero de inputs deve ser igual ao tamanho da mem√≥ria"
        );

        for i in 0..self.memory_trace.len() {
            self.memory_trace[i] =
                (1.0 - self.memory_alpha) * self.memory_trace[i] + self.memory_alpha * inputs[i];
        }
    }

    /// Calcula a novidade do padr√£o de entrada atual
    ///
    /// Novidade √© medida como a diferen√ßa absoluta m√©dia entre o input atual
    /// e a mem√≥ria contextual (padr√µes recentes). Valores altos indicam
    /// padr√µes inesperados ou n√£o familiares.
    ///
    /// # Argumentos
    /// * `inputs` - Vetor de sinais de entrada atual
    ///
    /// # Retorna
    /// Valor de novidade [0.0, ‚àû), onde 0 = completamente familiar
    pub fn compute_novelty(&self, inputs: &[f64]) -> f64 {
        assert_eq!(
            inputs.len(),
            self.memory_trace.len(),
            "N√∫mero de inputs deve ser igual ao tamanho da mem√≥ria"
        );

        // Calcula diferen√ßa absoluta m√©dia entre input e mem√≥ria
        let total_diff: f64 = inputs
            .iter()
            .zip(self.memory_trace.iter())
            .map(|(input, memory)| (input - memory).abs())
            .sum();

        // Normaliza pelo n√∫mero de inputs para manter escala consistente
        total_diff / inputs.len() as f64
    }

    /// Atualiza o priority da Glia baseado na novidade do input
    ///
    /// Priority aumenta com novidade, tornando o neur√≥nio mais sens√≠vel
    /// a padr√µes inesperados (mecanismo de aten√ß√£o emergente).
    ///
    /// F√≥rmula: priority = 1.0 + novelty * sensitivity_factor
    ///
    /// # Argumentos
    /// * `novelty` - Valor de novidade calculado
    /// * `sensitivity_factor` - Multiplicador de sensibilidade (padr√£o: 1.0)
    pub fn update_priority(&mut self, novelty: f64, sensitivity_factor: f64) {
        // Priority base √© 1.0, aumenta proporcionalmente √† novidade
        self.glia.priority = 1.0 + novelty * sensitivity_factor;

        // Limita priority a um m√°ximo razo√°vel para evitar instabilidade
        self.glia.priority = self.glia.priority.min(3.0);
    }

    /// Calcula o ganho de plasticidade baseado na energia dispon√≠vel
    ///
    /// Implementa energy-gated learning: neur√¥nios com baixa energia t√™m
    /// plasticidade fortemente reduzida, enquanto neur√¥nios com alta energia
    /// mant√™m plasticidade plena.
    ///
    /// CORRIGIDO: Modula√ß√£o mais forte e gradual
    /// F√≥rmula: gain = (e^2) para e < 0.5, depois suaviza para e > 0.5
    ///
    /// Janela pl√°stica:
    /// - e = 0.1: gain = 0.01 (1%, quase nulo)
    /// - e = 0.2: gain = 0.04 (4%)
    /// - e = 0.5: gain = 0.25 (25%)
    /// - e = 0.8: gain = 0.70 (70%)
    /// - e = 1.0: gain = 1.00 (100%)
    ///
    /// # Retorna
    /// Ganho de plasticidade [0.0, 1.0]
    fn compute_plasticity_gain(&self) -> f64 {
        let e = self.glia.energy_fraction();

        if e < 0.5 {
            // Regi√£o cr√≠tica: penaliza√ß√£o quadr√°tica
            // e=0.1 ‚Üí gain=0.01 (1%)
            // e=0.2 ‚Üí gain=0.04 (4%)
            // e=0.3 ‚Üí gain=0.09 (9%)
            // e=0.4 ‚Üí gain=0.16 (16%)
            e * e
        } else {
            // Regi√£o est√°vel: aprendizado pleno (‚â•50% energia)
            // Transi√ß√£o suave para 100%
            0.25 + 1.5 * (e - 0.5)
        }
    }

    /// Atualiza o limiar metapl√°stico BCM
    ///
    /// O BCM (Bienenstock-Cooper-Munro) ajusta o limiar de plasticidade
    /// baseado na atividade quadr√°tica m√©dia do neur√¥nio. Isso implementa
    /// metaplasticidade: neur√¥nios muito ativos aumentam seu limiar,
    /// tornando-se mais seletivos; neur√¥nios pouco ativos diminuem o limiar,
    /// tornando-se mais sens√≠veis.
    ///
    /// Œ∏_M = (1-Œ±) √ó Œ∏_M + Œ± √ó y¬≤
    ///
    /// # Argumentos
    /// * `fired` - Se o neur√¥nio disparou neste passo
    pub fn update_meta_threshold(&mut self, fired: bool) {
        let y = if fired { 1.0 } else { 0.0 };
        let y_sq = y * y;

        // Atualiza√ß√£o EMA do limiar metapl√°stico
        self.meta_threshold =
            (1.0 - self.meta_alpha) * self.meta_threshold + self.meta_alpha * y_sq;
    }

    /// Calcula o ganho de plasticidade BCM
    ///
    /// Modula a plasticidade baseado na rela√ß√£o entre atividade recente
    /// e o limiar metapl√°stico. Neur√¥nios muito acima do limiar t√™m
    /// plasticidade reduzida (evita satura√ß√£o), neur√¥nios abaixo t√™m
    /// plasticidade aumentada (facilita aprendizado).
    ///
    /// # Retorna
    /// Ganho de plasticidade [0.5, 1.5]
    fn compute_bcm_gain(&self) -> f64 {
        let y_bar = self.recent_firing_rate;
        let theta = self.meta_threshold.sqrt().max(1e-6); // Volta para escala de y

        // Diferen√ßa entre atividade e limiar
        let diff = y_bar - theta;

        // Ganho modulado: atividade alta ‚Üí ganho menor
        // Limites conservadores para n√£o quebrar STDP
        (1.0 - 0.5 * diff).clamp(0.5, 1.5)
    }

    /// Aplica plasticidade homeost√°tica periodicamente
    ///
    /// Implementa DOIS mecanismos biol√≥gicos simult√¢neos:
    /// 1. Synaptic Scaling (Peso): Ajusta "volume" das entradas
    /// 2. Intrinsic Plasticity (Threshold): Ajusta "sensibilidade" do neur√¥nio
    ///
    /// # Argumentos
    /// * `current_time` - Passo de tempo atual
    /// * `has_external_input` - Se h√° input externo ativo (>0.5)
    pub fn apply_homeostatic_plasticity(&mut self, current_time: i64, has_external_input: bool) {
        // Verifica se chegou a hora de aplicar homeostase
        if current_time - self.last_homeo_update < self.homeo_interval {
            return;
        }
        self.last_homeo_update = current_time;

        // üî• CORRE√á√ÉO: Permite homeostase mesmo sem input externo se FR for 0
        // (Neur√¥nios "mortos" precisam baixar threshold para procurar sinal)
        if !has_external_input && self.recent_firing_rate > 0.01 {
            return;
        }

        // Calcula erro de firing rate (positivo = hiperativo, negativo = hipoativo)
        let rate_error = self.recent_firing_rate - self.target_firing_rate;

        // S√≥ aplica se erro for significativo (> 1%)
        if rate_error.abs() < 0.01 {
            return;
        }

        // Modula erro pela energia
        let energy = self.glia.energy_fraction();
        let energy_weight = if energy < 0.3 { 0.3 } else { energy };
        let effective_error = rate_error * energy_weight;

        // MECANISMO 1: Synaptic Scaling (propor√ß√£o configur√°vel do esfor√ßo homeost√°tico)
        // Ajusta os pesos para tentar compensar o erro
        self.dendritoma.apply_synaptic_scaling(effective_error, self.homeo_eta * self.homeo_weight_ratio);

        // ‚ú® MECANISMO 2: Intrinsic Plasticity (propor√ß√£o configur√°vel do esfor√ßo homeost√°tico) ‚ú®
        // Ajusta o threshold.
        // Se rate_error < 0 (hipoativo) ‚Üí threshold DEVE CAIR (ficar mais sens√≠vel)
        // Se rate_error > 0 (hiperativo) ‚Üí threshold DEVE SUBIR (ficar menos sens√≠vel)
        let threshold_delta = effective_error * self.homeo_eta * self.homeo_threshold_ratio;

        self.threshold += threshold_delta;

        // Clamp adaptativo: evita colapso/negativa√ß√£o sem matar autorregula√ß√£o
        let energy_frac = self.glia.energy_fraction();
        // Overshoot aumenta o piso; decai lentamente a cada aplica√ß√£o
        self.overshoot_count *= 0.99;
        let min_threshold = (self.base_threshold * 0.02
            + (1.0 - energy_frac) * self.base_threshold * 0.3)
            * (1.0 + 0.1 * self.overshoot_count)
            .max(0.001);
        self.threshold = self.threshold.clamp(min_threshold, 5.0);
    }

    /// Processa um passo completo de atualiza√ß√£o do neur√≥nio
    ///
    /// Esta fun√ß√£o encapsula o fluxo completo:
    /// 1. Integra√ß√£o de sinais (Dendritoma)
    /// 2. Modula√ß√£o (Glia)
    /// 3. Decis√£o de disparo
    /// 4. Energy-gated learning (plasticidade controlada por energia)
    /// 5. Aprendizado (se disparou E tem energia suficiente)
    /// 6. Atualiza√ß√£o de estado
    ///
    /// # Argumentos
    /// * `inputs` - Vetor de sinais de entrada
    /// * `current_time` - Passo de tempo atual
    ///
    /// # Retorna
    /// O sinal de sa√≠da do neur√≥nio
    pub fn step(&mut self, inputs: &[f64], current_time: i64) -> f64 {
        // Fase 1: Integra√ß√£o
        let integrated_potential = self.dendritoma.integrate(inputs);

        // Fase 2: Modula√ß√£o glial
        let modulated_potential = self.glia.modulate(integrated_potential);

        // Determina se h√° input externo direto (para STDP gated)
        // Input externo = qualquer elemento > threshold de signific√¢ncia (0.5)
        let has_external_input = inputs.iter().any(|&inp| inp > 0.5);

        // Fase 3: Decis√£o de disparo
        self.decide_to_fire(modulated_potential, current_time, has_external_input);

        // Fase 4: Energy-gated + BCM learning - energia e metaplasticidade governam plasticidade
        let energy_gain = self.compute_plasticity_gain();
        let bcm_gain = self.compute_bcm_gain();

        // Combina√ß√£o multiplicativa: energia controla se aprende, BCM modula quanto
        let plasticity_gain = energy_gain * bcm_gain;
        self.dendritoma.set_plasticity_gain(plasticity_gain);

        // Fase 5: Aprendizado (apenas se disparou E tem energia/plasticidade)
        if self.is_firing && plasticity_gain > 0.0 {
            // Captura pesos antes do aprendizado para calcular custo
            let weights_before = self.dendritoma.weights.clone();

            self.dendritoma.apply_learning(inputs);

            // Calcula magnitude da mudan√ßa (custo metab√≥lico de plasticidade)
            let plasticity_cost: f64 = self.dendritoma.weights
                .iter()
                .zip(weights_before.iter())
                .map(|(w_new, w_old)| (w_new - w_old).abs())
                .sum();

            // Aprendizado consome energia proporcional √†s mudan√ßas
            self.glia.consume_plasticity_energy(plasticity_cost);
        }

        // Fase 6: Atualiza√ß√£o de estado
        self.glia.update_state(self.is_firing);
        self.update_memory(inputs);

        // Atualiza taxa de disparo recente (alpha = 0.01 para m√©dia de ~100 passos)
        let firing_value = if self.is_firing { 1.0 } else { 0.0 };
        self.recent_firing_rate = 0.99 * self.recent_firing_rate + 0.01 * firing_value;

        // Atualiza limiar metapl√°stico BCM
        self.update_meta_threshold(self.is_firing);

        // Fase 7: Plasticidade homeost√°tica (aplicada periodicamente)
        // CORRIGIDO: Passa has_external_input para evitar homeostase durante inatividade
        self.apply_homeostatic_plasticity(current_time, has_external_input);

        self.output_signal
    }

    /// √ötil para debugging e visualiza√ß√£o
    pub fn get_modulated_potential(&self, inputs: &[f64]) -> f64 {
        let integrated = self.dendritoma.integrate(inputs);
        self.glia.modulate(integrated)
    }

    /// Define o per√≠odo refrat√°rio
    pub fn set_refractory_period(&mut self, period: i64) {
        self.refractory_period = period;
    }

    /// Retorna o limiar base configurado na cria√ß√£o
    pub fn base_threshold(&self) -> f64 {
        self.base_threshold
    }

    /// Define a taxa de atualiza√ß√£o da mem√≥ria
    pub fn set_memory_alpha(&mut self, alpha: f64) {
        self.memory_alpha = alpha.clamp(0.0, 1.0);
    }

    /// Retorna o tempo do √∫ltimo spike (para STDP)
    ///
    /// # Retorna
    /// `Some(time)` se o neur√¥nio j√° disparou, `None` caso contr√°rio
    pub fn get_last_spike_time(&self) -> Option<i64> {
        if self.last_fire_time >= 0 {
            Some(self.last_fire_time)
        } else {
            None
        }
    }

    /// Retorna uma refer√™ncia ao hist√≥rico de spikes (para an√°lise)
    pub fn spike_history(&self) -> &VecDeque<i64> {
        &self.spike_history
    }

    /// Ajusta metabolismo para modo sono (baixo consumo, alta recupera√ß√£o)
    pub fn enter_sleep_mode(&mut self) {
        self.glia.enter_sleep_mode();
    }

    /// Restaura metabolismo para modo vig√≠lia (consumo normal)
    pub fn exit_sleep_mode(&mut self) {
        self.glia.exit_sleep_mode();
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use approx::assert_relative_eq;

    #[test]
    fn test_nenv_initialization() {
        let neuron = NENV::excitatory(0, 10, 0.5);

        assert_eq!(neuron.id, 0);
        assert_eq!(neuron.neuron_type, NeuronType::Excitatory);
        assert_eq!(neuron.threshold, 0.5);
        assert_eq!(neuron.memory_trace.len(), 10);
        assert!(!neuron.is_firing);
        assert_eq!(neuron.output_signal, 0.0);
    }

    #[test]
    fn test_excitatory_neuron_output() {
        let mut neuron = NENV::excitatory(0, 2, 1.5); // Limiar ajustado

        // Configura pesos n√£o normalizados para garantir disparo
        // potencial = 1.0*1.0 + 1.0*1.0 = 2.0
        // modulado = 2.0 * 1.0 (energia_max) * 1.0 (priority) = 2.0 > 1.5
        neuron.dendritoma.weights = vec![1.0, 1.0];
        neuron.glia.priority = 1.0;

        let inputs = vec![1.0, 1.0];
        let potential = neuron.get_modulated_potential(&inputs);
        neuron.decide_to_fire(potential, 0);

        assert!(neuron.is_firing);
        assert_eq!(neuron.output_signal, 1.0);
    }

    #[test]
    fn test_inhibitory_neuron_output() {
        let mut neuron = NENV::inhibitory(0, 2, 1.5); // Limiar ajustado

        // Configura pesos n√£o normalizados para garantir disparo
        neuron.dendritoma.weights = vec![1.0, 1.0];
        neuron.glia.priority = 1.0;

        let inputs = vec![1.0, 1.0];
        let potential = neuron.get_modulated_potential(&inputs);
        neuron.decide_to_fire(potential, 0, false);

        assert!(neuron.is_firing);
        assert_eq!(neuron.output_signal, -1.0);
    }

    #[test]
    fn test_refractory_period() {
        let mut neuron = NENV::excitatory(0, 2, 1.5); // Limiar ajustado
        neuron.dendritoma.weights = vec![1.0, 1.0];
        neuron.glia.priority = 1.0;
        neuron.set_refractory_period(5);

        let inputs = vec![1.0, 1.0];

        // Primeiro disparo no tempo 0
        let potential = neuron.get_modulated_potential(&inputs);
        neuron.decide_to_fire(potential, 0, false);
        assert!(neuron.is_firing);

        // Tentativa de disparo no tempo 2 (dentro do per√≠odo refrat√°rio)
        let potential = neuron.get_modulated_potential(&inputs);
        neuron.decide_to_fire(potential, 2, false);
        assert!(!neuron.is_firing);

        // Tentativa de disparo no tempo 6 (fora do per√≠odo refrat√°rio)
        let potential = neuron.get_modulated_potential(&inputs);
        neuron.decide_to_fire(potential, 6, false);
        assert!(neuron.is_firing);
    }

    #[test]
    fn test_memory_update() {
        let mut neuron = NENV::excitatory(0, 3, 0.5);
        neuron.set_memory_alpha(0.5); // Alta taxa para teste r√°pido

        let inputs1 = vec![1.0, 0.0, 0.0];
        neuron.update_memory(&inputs1);

        // Ap√≥s uma atualiza√ß√£o, mem√≥ria deve ser 0.5 * inputs1
        assert_relative_eq!(neuron.memory_trace[0], 0.5, epsilon = 1e-10);
        assert_relative_eq!(neuron.memory_trace[1], 0.0, epsilon = 1e-10);

        let inputs2 = vec![0.0, 1.0, 0.0];
        neuron.update_memory(&inputs2);

        // Mem√≥ria do primeiro canal decai, segundo canal aumenta
        assert_relative_eq!(neuron.memory_trace[0], 0.25, epsilon = 1e-10);
        assert_relative_eq!(neuron.memory_trace[1], 0.5, epsilon = 1e-10);
    }

    #[test]
    fn test_threshold_prevents_firing() {
        let mut neuron = NENV::excitatory(0, 2, 10.0); // Limiar muito alto
        neuron.dendritoma.weights = vec![0.5, 0.5];

        let inputs = vec![1.0, 1.0];
        let potential = neuron.get_modulated_potential(&inputs);

        neuron.decide_to_fire(potential, 0, false);
        assert!(!neuron.is_firing);
    }

    #[test]
    fn test_energy_depletion_prevents_firing() {
        let mut neuron = NENV::excitatory(0, 2, 0.1);
        neuron.dendritoma.weights = vec![1.0, 1.0];
        neuron.glia.energy = 0.0; // Sem energia

        let inputs = vec![1.0, 1.0];
        let potential = neuron.get_modulated_potential(&inputs);

        // Potencial integrado √© alto, mas modula√ß√£o reduz a zero
        assert_relative_eq!(potential, 0.0, epsilon = 1e-10);

        neuron.decide_to_fire(potential, 0, false);
        assert!(!neuron.is_firing);
    }

    // === Testes v0.2.0: Priority & Alert Level ===

    #[test]
    fn test_compute_novelty_zero_for_familiar() {
        let mut neuron = NENV::excitatory(0, 3, 0.5);

        // Define mem√≥ria como um padr√£o espec√≠fico
        neuron.memory_trace = vec![0.5, 0.3, 0.2];

        // Input id√™ntico √† mem√≥ria
        let inputs = vec![0.5, 0.3, 0.2];
        let novelty = neuron.compute_novelty(&inputs);

        // Novidade deve ser zero (completamente familiar)
        assert_relative_eq!(novelty, 0.0, epsilon = 1e-10);
    }

    #[test]
    fn test_compute_novelty_high_for_novel() {
        let mut neuron = NENV::excitatory(0, 3, 0.5);

        // Mem√≥ria com zeros (nenhum input recente)
        neuron.memory_trace = vec![0.0, 0.0, 0.0];

        // Input forte e completamente novo
        let inputs = vec![1.0, 1.0, 1.0];
        let novelty = neuron.compute_novelty(&inputs);

        // Novidade deve ser 1.0 (m√©dia de diferen√ßas absolutas)
        assert_relative_eq!(novelty, 1.0, epsilon = 1e-10);
    }

    #[test]
    fn test_compute_novelty_partial() {
        let mut neuron = NENV::excitatory(0, 4, 0.5);

        neuron.memory_trace = vec![0.5, 0.5, 0.5, 0.5];
        let inputs = vec![1.0, 0.0, 1.0, 0.0];

        let novelty = neuron.compute_novelty(&inputs);

        // Diferen√ßas: |1.0-0.5| + |0.0-0.5| + |1.0-0.5| + |0.0-0.5| = 2.0
        // M√©dia: 2.0 / 4 = 0.5
        assert_relative_eq!(novelty, 0.5, epsilon = 1e-10);
    }

    #[test]
    fn test_update_priority_increases_with_novelty() {
        let mut neuron = NENV::excitatory(0, 2, 0.5);

        // Priority inicial deve ser 1.0
        assert_eq!(neuron.glia.priority, 1.0);

        // Atualiza com novelty=0.5 e sensitivity_factor=1.0
        neuron.update_priority(0.5, 1.0);

        // Priority = 1.0 + 0.5*1.0 = 1.5
        assert_relative_eq!(neuron.glia.priority, 1.5, epsilon = 1e-10);
    }

    #[test]
    fn test_update_priority_sensitivity_factor() {
        let mut neuron = NENV::excitatory(0, 2, 0.5);

        // Sensitivity factor = 2.0 (mais sens√≠vel)
        neuron.update_priority(0.5, 2.0);

        // Priority = 1.0 + 0.5*2.0 = 2.0
        assert_relative_eq!(neuron.glia.priority, 2.0, epsilon = 1e-10);
    }

    #[test]
    fn test_update_priority_clamps_at_max() {
        let mut neuron = NENV::excitatory(0, 2, 0.5);

        // Novelty muito alto com sensitivity alto
        neuron.update_priority(10.0, 1.0);

        // Priority deve ser limitado a 3.0
        assert_eq!(neuron.glia.priority, 3.0);
    }

    #[test]
    fn test_priority_modulates_potential() {
        let mut neuron = NENV::excitatory(0, 2, 0.1);
        neuron.dendritoma.weights = vec![0.7071067811865475, 0.7071067811865475];
        neuron.glia.energy = 100.0; // Energia m√°xima
        neuron.glia.priority = 2.0; // Priority dobrado

        let inputs = vec![1.0, 1.0];
        let potential = neuron.get_modulated_potential(&inputs);

        // Sem priority: ~1.41
        // Com priority=2.0: ~2.82
        assert!(potential > 2.5);
        assert!(potential < 3.0);
    }

    #[test]
    fn test_priority_enables_firing() {
        let mut neuron = NENV::excitatory(0, 2, 1.5); // Limiar alto
        neuron.dendritoma.weights = vec![0.7071067811865475, 0.7071067811865475];
        neuron.glia.priority = 1.0; // Priority normal

        let inputs = vec![1.0, 1.0];

        // Sem priority alto, n√£o dispara
        let potential = neuron.get_modulated_potential(&inputs);
        neuron.decide_to_fire(potential, 0, false);
        assert!(!neuron.is_firing);

        // Com priority alto, dispara
        neuron.glia.priority = 2.0;
        let potential_boosted = neuron.get_modulated_potential(&inputs);
        neuron.decide_to_fire(potential_boosted, 1, false);
        assert!(neuron.is_firing);
    }

    // === Testes v0.4.0: Spike History & STDP Support ===

    #[test]
    fn test_get_last_spike_time_none_initially() {
        let neuron = NENV::excitatory(0, 2, 0.5);

        // Neur√¥nio nunca disparou, deve retornar None
        assert_eq!(neuron.get_last_spike_time(), None);
    }

    #[test]
    fn test_get_last_spike_time_after_firing() {
        let mut neuron = NENV::excitatory(0, 2, 0.1);
        neuron.dendritoma.weights = vec![1.0, 1.0];
        neuron.glia.priority = 1.0;

        let inputs = vec![1.0, 1.0];

        // Dispara no tempo 100
        let potential = neuron.get_modulated_potential(&inputs);
        neuron.decide_to_fire(potential, 100, false);

        assert!(neuron.is_firing);
        assert_eq!(neuron.get_last_spike_time(), Some(100));
    }

    #[test]
    fn test_spike_history_updates_on_firing() {
        let mut neuron = NENV::excitatory(0, 2, 0.1);
        neuron.dendritoma.weights = vec![1.0, 1.0];
        neuron.glia.priority = 1.0;

        let inputs = vec![1.0, 1.0];

        // Inicialmente vazio
        assert_eq!(neuron.spike_history().len(), 0);

        // Dispara no tempo 10
        let potential = neuron.get_modulated_potential(&inputs);
        neuron.decide_to_fire(potential, 10, false);
        assert_eq!(neuron.spike_history().len(), 1);
        assert_eq!(neuron.spike_history()[0], 10);

        // Dispara no tempo 20
        let potential = neuron.get_modulated_potential(&inputs);
        neuron.decide_to_fire(potential, 20, false);
        assert_eq!(neuron.spike_history().len(), 2);
        assert_eq!(neuron.spike_history()[1], 20);
    }

    #[test]
    fn test_spike_history_limits_to_10_spikes() {
        let mut neuron = NENV::excitatory(0, 2, 0.1);
        neuron.dendritoma.weights = vec![1.0, 1.0];
        neuron.glia.priority = 1.0;
        neuron.set_refractory_period(0); // Remove per√≠odo refrat√°rio para teste

        let inputs = vec![1.0, 1.0];

        // Dispara 15 vezes
        for t in 0..15 {
            let potential = neuron.get_modulated_potential(&inputs);
            neuron.decide_to_fire(potential, t * 10, false);
        }

        // Deve manter apenas os √∫ltimos 10 spikes
        assert_eq!(neuron.spike_history().len(), 10);

        // O primeiro spike deve ser do tempo 50 (√≠ndice 5)
        assert_eq!(neuron.spike_history()[0], 50);

        // O √∫ltimo spike deve ser do tempo 140 (√≠ndice 14)
        assert_eq!(neuron.spike_history()[9], 140);
    }

    #[test]
    fn test_spike_history_empty_when_no_firing() {
        let mut neuron = NENV::excitatory(0, 2, 10.0); // Limiar muito alto
        neuron.dendritoma.weights = vec![0.1, 0.1];

        let inputs = vec![1.0, 1.0];

        // Tenta disparar mas n√£o consegue
        for t in 0..5 {
            let potential = neuron.get_modulated_potential(&inputs);
            neuron.decide_to_fire(potential, t * 10, false);
        }

        // Hist√≥rico deve permanecer vazio
        assert_eq!(neuron.spike_history().len(), 0);
    }

    #[test]
    fn test_spike_history_respects_refractory_period() {
        let mut neuron = NENV::excitatory(0, 2, 0.1);
        neuron.dendritoma.weights = vec![1.0, 1.0];
        neuron.glia.priority = 1.0;
        neuron.set_refractory_period(5);

        let inputs = vec![1.0, 1.0];

        // Dispara no tempo 0
        let potential = neuron.get_modulated_potential(&inputs);
        neuron.decide_to_fire(potential, 0, false);
        assert_eq!(neuron.spike_history().len(), 1);

        // Tenta disparar no tempo 2 (dentro do per√≠odo refrat√°rio)
        let potential = neuron.get_modulated_potential(&inputs);
        neuron.decide_to_fire(potential, 2, false);
        assert_eq!(neuron.spike_history().len(), 1); // N√£o deve adicionar

        // Dispara no tempo 6 (fora do per√≠odo refrat√°rio)
        let potential = neuron.get_modulated_potential(&inputs);
        neuron.decide_to_fire(potential, 6, false);
        assert_eq!(neuron.spike_history().len(), 2); // Deve adicionar
        assert_eq!(neuron.spike_history()[1], 6);
    }
}
