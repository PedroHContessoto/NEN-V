# Relat√≥rio de An√°lise e Melhoria
## NEN-V: Neuromorphic Energy-based Neural Virtual Model v2.0

**Data:** Novembro 2025  
**Objetivo:** An√°lise completa para evolu√ß√£o da rede neural biologicamente inspirada  
**Foco:** Maximizar intelig√™ncia respeitando autonomia adaptativa

---

## Sum√°rio Executivo

O projeto NEN-V representa uma implementa√ß√£o sofisticada de rede neural biologicamente plaus√≠vel, incorporando mecanismos avan√ßados como STDP assim√©trico, eligibility traces, short-term plasticity e neuromodula√ß√£o. A arquitetura atual demonstra maturidade t√©cnica consider√°vel, por√©m identificamos **lacunas cr√≠ticas** que limitam a emerg√™ncia de comportamentos verdadeiramente inteligentes e aut√¥nomos.

Este relat√≥rio apresenta uma an√°lise sistem√°tica de cada componente, identificando aus√™ncias estruturais e propondo melhorias que respeitam o princ√≠pio fundamental: **a rede deve adaptar-se autonomamente ao meio**.

---

## Parte I: Diagn√≥stico do Estado Atual

### 1.1 Arquitetura Implementada

| Componente | Status | Qualidade |
|------------|--------|-----------|
| Neur√¥nio (NENV) | ‚úÖ Completo | Alta |
| Dendritoma (Sinapses) | ‚úÖ Completo | Alta |
| Glia (Metabolismo) | ‚úÖ Completo | M√©dia-Alta |
| Network (Orquestra√ß√£o) | ‚úÖ Completo | M√©dia |
| Neuromodula√ß√£o | ‚úÖ B√°sico | M√©dia |
| AutoConfig | ‚úÖ Completo | Alta |
| Adapta√ß√£o Runtime | ‚úÖ Completo | Alta |

### 1.2 Mecanismos Biol√≥gicos Presentes

**Plasticidade Sin√°ptica:**
- ‚úÖ STDP (Spike-Timing-Dependent Plasticity) assim√©trico
- ‚úÖ iSTDP (Inhibitory STDP)
- ‚úÖ Eligibility Traces para 3-factor learning
- ‚úÖ Short-Term Plasticity (facilita√ß√£o/depress√£o)
- ‚úÖ Synaptic Tagging and Capture

**Homeostase:**
- ‚úÖ Synaptic Scaling
- ‚úÖ Intrinsic Plasticity (threshold adaptativo)
- ‚úÖ Metaplasticidade BCM
- ‚úÖ Controlador PID global

**Metabolismo:**
- ‚úÖ Sistema energ√©tico com reserva
- ‚úÖ Energy-gated learning
- ‚úÖ Adapta√ß√£o metab√≥lica

**Din√¢micas de Rede:**
- ‚úÖ Competi√ß√£o lateral
- ‚úÖ Normaliza√ß√£o competitiva
- ‚úÖ Ciclos de sono/consolida√ß√£o

---

## Parte II: Lacunas Cr√≠ticas Identificadas

### 2.1 Aus√™ncia de Mem√≥ria de Trabalho (Working Memory)

**Problema:** A rede atual n√£o possui mecanismo para manter informa√ß√£o ativa temporariamente sem consolida√ß√£o permanente.

**Impacto:** 
- Incapacidade de realizar racioc√≠nio sequencial
- Perda de contexto em tarefas multi-step
- Impossibilidade de manipular informa√ß√£o "in-flight"

**Evid√™ncia no c√≥digo:**
```rust
// network.rs - N√£o h√° buffer de atividade sustentada
// A informa√ß√£o flui e decai sem persist√™ncia controlada
```

### 2.2 Aus√™ncia de Aten√ß√£o Seletiva Verdadeira

**Problema:** O mecanismo de `priority` na Glia √© reativo (baseado em novidade), mas n√£o h√° aten√ß√£o top-down control√°vel.

**Impacto:**
- Rede responde apenas a est√≠mulos salientes
- N√£o consegue focar em aspectos espec√≠ficos sob demanda
- Aus√™ncia de filtragem consciente de informa√ß√£o

**C√≥digo atual:**
```rust
// nenv.rs linha ~200
pub fn update_priority(&mut self, novelty: f64, sensitivity_factor: f64) {
    self.glia.priority = 1.0 + novelty * sensitivity_factor;
    // Apenas bottom-up, sem controle top-down
}
```

### 2.3 Aus√™ncia de Hierarquia Temporal

**Problema:** Todos os neur√¥nios operam na mesma escala temporal. N√£o h√° integra√ß√£o multi-escala.

**Impacto:**
- Incapacidade de aprender padr√µes em diferentes escalas
- Sem abstra√ß√£o temporal (eventos vs. epis√≥dios vs. narrativas)
- Limita√ß√£o em tarefas com depend√™ncias de longo prazo

### 2.4 Aus√™ncia de Predi√ß√£o/Modelo Interno

**Problema:** A rede √© puramente reativa. N√£o h√° mecanismo de predi√ß√£o forward.

**Impacto:**
- Sem antecipa√ß√£o de consequ√™ncias
- Aprendizado limitado a corre√ß√£o de erro post-hoc
- Impossibilidade de planejamento

### 2.5 Aus√™ncia de Estruturas de Binding

**Problema:** N√£o h√° mecanismo para vincular features dispersas em representa√ß√µes unificadas.

**Impacto:**
- Objetos/conceitos n√£o emergem como entidades coerentes
- Problema de binding cl√°ssico n√£o resolvido
- Representa√ß√µes fragmentadas

### 2.6 Neuromodula√ß√£o Simplificada

**Problema:** Sistema atual trata neuromoduladores de forma global uniforme.

**C√≥digo atual:**
```rust
// neuromodulation.rs
// Dopamina aplica-se uniformemente a toda rede
pub fn process_reward(&mut self, actual_reward: f64) -> f64 {
    // Sem targeting espacial ou temporal
}
```

**Impacto:**
- Cr√©dito distribu√≠do uniformemente (n√£o espec√≠fico)
- Sem modula√ß√£o diferencial por regi√£o
- Perda de especificidade funcional

### 2.7 Aus√™ncia de Replay Estruturado

**Problema:** O replay durante sono √© baseado em ru√≠do + atividade recente, n√£o em sequ√™ncias epis√≥dicas.

**C√≥digo atual:**
```rust
// network.rs - Sleep replay
let noise_prob = replay_noise + (neuron.saved_awake_activity * 1.0);
if rand::random::<f64>() < noise_prob {
    // Replay estoc√°stico, n√£o estruturado
}
```

### 2.8 Aus√™ncia de Infer√™ncia Causal

**Problema:** STDP captura correla√ß√µes temporais, mas n√£o distingue causalidade verdadeira.

**Impacto:**
- Correla√ß√µes esp√∫rias s√£o aprendidas
- Sem interven√ß√£o/imagina√ß√£o contrafactual
- Generaliza√ß√µes incorretas

---

## Parte III: Propostas de Melhoria

### 3.1 Implementar Working Memory via Atividade Persistente

**Proposta:** Adicionar popula√ß√£o de neur√¥nios com din√¢micas de atrator.

```rust
// Novo arquivo: working_memory.rs

/// Pool de Working Memory com din√¢mica de atrator
pub struct WorkingMemoryPool {
    /// Neur√¥nios com auto-excita√ß√£o controlada
    neurons: Vec<WMNeuron>,
    
    /// For√ßa da recorr√™ncia (mant√©m atividade)
    recurrent_strength: f64,
    
    /// Inibi√ß√£o lateral (limita capacidade)
    lateral_inhibition: f64,
    
    /// Decaimento natural (esquecimento controlado)
    decay_rate: f64,
    
    /// Slots de mem√≥ria ativos
    active_slots: Vec<usize>,
    
    /// Capacidade m√°xima (analogia: 7¬±2 chunks)
    max_capacity: usize,
}

impl WorkingMemoryPool {
    /// Codifica padr√£o em slot dispon√≠vel
    pub fn encode(&mut self, pattern: &[f64]) -> Option<usize> {
        if self.active_slots.len() >= self.max_capacity {
            return None; // Capacidade esgotada
        }
        // Encontra neur√¥nios com maior match
        // Ativa recorr√™ncia para manter
    }
    
    /// Mant√©m padr√µes ativos (chamado a cada step)
    pub fn sustain(&mut self) {
        for slot in &self.active_slots {
            // Reinjeta atividade via recorr√™ncia
            // Aplica decaimento competitivo
        }
    }
    
    /// Libera slot (forget controlado)
    pub fn release(&mut self, slot: usize) {
        // Remove da lista ativa
        // Permite decaimento natural
    }
}
```

**Integra√ß√£o com autonomia:** O sistema decide autonomamente o que manter baseado em relev√¢ncia (conex√£o com neuromodula√ß√£o).

---

### 3.2 Implementar Aten√ß√£o Top-Down

**Proposta:** Sistema de aten√ß√£o bidirecional com controle executivo.

```rust
// Novo arquivo: attention.rs

pub struct AttentionSystem {
    /// Mapa de sali√™ncia bottom-up (j√° existe parcialmente)
    saliency_map: Vec<f64>,
    
    /// Vetor de aten√ß√£o top-down (NOVO)
    attention_vector: Vec<f64>,
    
    /// Fonte do controle top-down (neur√¥nios "executivos")
    executive_indices: Vec<usize>,
    
    /// Peso relativo bottom-up vs top-down
    top_down_weight: f64,
    
    /// Hist√≥rico de foco (para switching cost)
    focus_history: VecDeque<usize>,
}

impl AttentionSystem {
    /// Computa aten√ß√£o combinada
    pub fn compute_attention(&self) -> Vec<f64> {
        self.saliency_map.iter()
            .zip(self.attention_vector.iter())
            .map(|(bu, td)| {
                let bottom_up = bu * (1.0 - self.top_down_weight);
                let top_down = td * self.top_down_weight;
                bottom_up + top_down
            })
            .collect()
    }
    
    /// Atualiza foco baseado em objetivo (goal-directed)
    pub fn focus_on(&mut self, target_features: &[f64]) {
        // Neur√¥nios executivos geram attention_vector
        // Baseado em match com target_features
    }
    
    /// Modula ganho de neur√¥nios baseado em aten√ß√£o
    pub fn apply_gain_modulation(&self, network: &mut Network) {
        let attention = self.compute_attention();
        for (i, neuron) in network.neurons.iter_mut().enumerate() {
            neuron.glia.priority *= 1.0 + attention[i];
        }
    }
}
```

**Integra√ß√£o com autonomia:** O sistema aprende quais features s√£o relevantes para cada contexto via reinforcement.

---

### 3.3 Implementar Hierarquia Temporal

**Proposta:** M√∫ltiplas camadas com constantes de tempo diferentes.

```rust
// Modifica√ß√£o em params.rs e architecture.rs

/// Configura√ß√£o de camada temporal
pub struct TemporalLayerConfig {
    /// Constante de tempo da camada (ms simulados)
    pub tau: f64,
    
    /// Taxa de amostragem relativa
    pub sampling_rate: usize,
    
    /// Janela de integra√ß√£o
    pub integration_window: usize,
}

impl DerivedArchitecture {
    /// Deriva arquitetura multi-temporal
    pub fn with_temporal_hierarchy(task: &TaskSpec) -> Self {
        let layers = vec![
            TemporalLayerConfig { tau: 10.0, sampling_rate: 1, integration_window: 5 },    // Fast
            TemporalLayerConfig { tau: 50.0, sampling_rate: 5, integration_window: 20 },   // Medium
            TemporalLayerConfig { tau: 200.0, sampling_rate: 20, integration_window: 50 }, // Slow
        ];
        // Configura neur√¥nios com taus diferentes por camada
    }
}

// Em nenv.rs - Adicionar tau vari√°vel
pub struct NENV {
    // ... campos existentes ...
    
    /// Constante de tempo do neur√¥nio (integra√ß√£o temporal)
    pub temporal_tau: f64,
    
    /// Buffer de integra√ß√£o temporal
    temporal_buffer: VecDeque<f64>,
}
```

**Integra√ß√£o com autonomia:** Camadas mais lentas naturalmente capturam padr√µes de maior escala sem supervis√£o.

---

### 3.4 Implementar Modelo Preditivo (Predictive Coding)

**Proposta:** Adicionar predi√ß√µes forward e sinais de erro.

```rust
// Novo arquivo: predictive.rs

pub struct PredictiveLayer {
    /// Predi√ß√µes para o pr√≥ximo timestep
    predictions: Vec<f64>,
    
    /// Erros de predi√ß√£o (input - prediction)
    prediction_errors: Vec<f64>,
    
    /// Pesos do modelo generativo
    generative_weights: Vec<Vec<f64>>,
    
    /// Precis√£o (confidence) de cada predi√ß√£o
    precision: Vec<f64>,
}

impl PredictiveLayer {
    /// Gera predi√ß√£o baseada no estado atual
    pub fn predict(&mut self, current_state: &[f64]) {
        for i in 0..self.predictions.len() {
            self.predictions[i] = current_state.iter()
                .zip(self.generative_weights[i].iter())
                .map(|(s, w)| s * w)
                .sum();
        }
    }
    
    /// Computa erro de predi√ß√£o
    pub fn compute_error(&mut self, actual_input: &[f64]) {
        for i in 0..self.prediction_errors.len() {
            self.prediction_errors[i] = actual_input[i] - self.predictions[i];
            // Peso pelo precision (confian√ßa)
            self.prediction_errors[i] *= self.precision[i];
        }
    }
    
    /// Atualiza modelo baseado em erros
    pub fn update_model(&mut self, learning_rate: f64) {
        // Aprende a prever melhor
        // Minimiza free energy (variacional)
    }
}
```

**Integra√ß√£o com autonomia:** O sistema aprende seu pr√≥prio modelo do mundo, melhorando predi√ß√µes autonomamente.

---

### 3.5 Implementar Sincroniza√ß√£o Temporal (Binding)

**Proposta:** Usar oscila√ß√µes para vincular representa√ß√µes.

```rust
// Novo arquivo: oscillations.rs

pub struct OscillatoryBinding {
    /// Fase de cada neur√¥nio [0, 2œÄ]
    phases: Vec<f64>,
    
    /// Frequ√™ncia natural de cada neur√¥nio
    natural_frequencies: Vec<f64>,
    
    /// For√ßa de acoplamento entre neur√¥nios
    coupling_strength: f64,
    
    /// Frequ√™ncia base (gamma ~40Hz)
    base_frequency: f64,
}

impl OscillatoryBinding {
    /// Atualiza fases (Kuramoto model)
    pub fn update_phases(&mut self, connectivity: &[Vec<u8>]) {
        let mut new_phases = self.phases.clone();
        
        for i in 0..self.phases.len() {
            let mut coupling_sum = 0.0;
            for j in 0..self.phases.len() {
                if connectivity[i][j] == 1 {
                    coupling_sum += (self.phases[j] - self.phases[i]).sin();
                }
            }
            new_phases[i] = self.phases[i] 
                + self.natural_frequencies[i] 
                + self.coupling_strength * coupling_sum;
        }
        
        self.phases = new_phases;
    }
    
    /// Detecta assemblies sincronizadas
    pub fn detect_assemblies(&self, coherence_threshold: f64) -> Vec<Vec<usize>> {
        // Agrupa neur√¥nios com fases similares
        // Retorna conjuntos de neur√¥nios "bound"
    }
    
    /// Modula disparo baseado em fase
    pub fn phase_modulation(&self, neuron_idx: usize) -> f64 {
        // Neur√¥nios disparam preferencialmente em certas fases
        (self.phases[neuron_idx]).cos() * 0.5 + 0.5
    }
}
```

**Integra√ß√£o com autonomia:** Sincroniza√ß√£o emerge naturalmente de atividade correlacionada.

---

### 3.6 Expandir Sistema de Neuromodula√ß√£o

**Proposta:** Neuromodula√ß√£o espacialmente espec√≠fica com m√∫ltiplos receptores.

```rust
// Modifica√ß√£o em neuromodulation.rs

pub struct EnhancedNeuromodulation {
    /// N√≠veis globais (existente)
    pub global_levels: HashMap<NeuromodulatorType, f64>,
    
    /// NOVO: N√≠veis locais por regi√£o
    pub local_levels: HashMap<NeuromodulatorType, Vec<f64>>,
    
    /// NOVO: Tipos de receptores por neur√¥nio
    pub receptor_density: Vec<ReceptorProfile>,
    
    /// NOVO: Proje√ß√µes dopamin√©rgicas espec√≠ficas
    pub da_projections: Vec<(usize, Vec<usize>)>, // (fonte, alvos)
}

#[derive(Clone)]
pub struct ReceptorProfile {
    /// D1-like (excitat√≥rio, facilita LTP)
    pub d1_density: f64,
    
    /// D2-like (inibit√≥rio, facilita LTD)
    pub d2_density: f64,
    
    /// Alpha-adren√©rgico (norepinefrina)
    pub alpha_density: f64,
    
    /// Beta-adren√©rgico (norepinefrina)
    pub beta_density: f64,
}

impl EnhancedNeuromodulation {
    /// Libera dopamina com targeting espacial
    pub fn release_targeted_dopamine(&mut self, source: usize, amount: f64) {
        if let Some((_, targets)) = self.da_projections.iter()
            .find(|(s, _)| *s == source) 
        {
            for &target in targets {
                self.local_levels
                    .entry(NeuromodulatorType::Dopamine)
                    .or_insert_with(|| vec![0.0; self.local_levels.len()])
                    [target] += amount;
            }
        }
    }
    
    /// Computa efeito da dopamina considerando receptores
    pub fn compute_da_effect(&self, neuron_idx: usize) -> (f64, f64) {
        let da_level = self.local_levels
            .get(&NeuromodulatorType::Dopamine)
            .map(|v| v[neuron_idx])
            .unwrap_or(0.0);
        
        let profile = &self.receptor_density[neuron_idx];
        
        let ltp_modulation = da_level * profile.d1_density;
        let ltd_modulation = da_level * profile.d2_density;
        
        (ltp_modulation, ltd_modulation)
    }
}
```

---

### 3.7 Implementar Replay Epis√≥dico Estruturado

**Proposta:** Buffer de experi√™ncias com replay sequencial.

```rust
// Novo arquivo: episodic_memory.rs

pub struct EpisodicBuffer {
    /// Sequ√™ncias de estados armazenadas
    episodes: Vec<Episode>,
    
    /// Capacidade m√°xima
    max_episodes: usize,
    
    /// √çndice de prioridade para replay (baseado em TD-error)
    priority_index: Vec<(usize, f64)>,
}

pub struct Episode {
    /// Sequ√™ncia de estados da rede
    states: Vec<NetworkSnapshot>,
    
    /// Rewards associados
    rewards: Vec<f64>,
    
    /// TD-errors (para prioritized replay)
    td_errors: Vec<f64>,
    
    /// Timestamp de cria√ß√£o
    timestamp: i64,
    
    /// N√∫mero de replays j√° realizados
    replay_count: usize,
}

impl EpisodicBuffer {
    /// Inicia grava√ß√£o de novo epis√≥dio
    pub fn start_episode(&mut self) -> usize {
        let episode = Episode::new();
        self.episodes.push(episode);
        self.episodes.len() - 1
    }
    
    /// Adiciona estado ao epis√≥dio atual
    pub fn record_state(&mut self, episode_id: usize, snapshot: NetworkSnapshot, reward: f64) {
        if let Some(episode) = self.episodes.get_mut(episode_id) {
            episode.states.push(snapshot);
            episode.rewards.push(reward);
        }
    }
    
    /// Seleciona epis√≥dio para replay (prioritized)
    pub fn select_for_replay(&self) -> Option<&Episode> {
        // Weighted sampling baseado em TD-error e rec√™ncia
    }
    
    /// Executa replay de epis√≥dio na rede
    pub fn replay_episode(&self, episode: &Episode, network: &mut Network) {
        for (i, state) in episode.states.iter().enumerate() {
            // Reinjeta padr√£o de ativa√ß√£o
            network.inject_state(state);
            
            // Permite STDP operar na sequ√™ncia
            network.update(&[]);
            
            // Modula por TD-error do passo
            let td = episode.td_errors.get(i).unwrap_or(&0.0);
            network.propagate_reward(*td);
        }
    }
}
```

---

### 3.8 Adicionar Mecanismo de Curiosidade Intr√≠nseca

**Proposta:** Recompensa interna por redu√ß√£o de incerteza.

```rust
// Novo arquivo: intrinsic_motivation.rs

pub struct CuriosityModule {
    /// Modelo forward (prediz pr√≥ximo estado)
    forward_model: PredictiveLayer,
    
    /// Modelo inverse (prediz a√ß√£o dado estados)
    inverse_model: InverseModel,
    
    /// Erro de predi√ß√£o m√©dio (EMA)
    avg_prediction_error: f64,
    
    /// Escala da recompensa intr√≠nseca
    curiosity_scale: f64,
}

impl CuriosityModule {
    /// Computa recompensa intr√≠nseca (curiosity)
    pub fn compute_intrinsic_reward(
        &mut self, 
        state: &[f64], 
        action: &[f64], 
        next_state: &[f64]
    ) -> f64 {
        // Prediz pr√≥ximo estado
        self.forward_model.predict_from_state_action(state, action);
        
        // Erro de predi√ß√£o
        let pred_error: f64 = self.forward_model.predictions.iter()
            .zip(next_state.iter())
            .map(|(p, n)| (p - n).powi(2))
            .sum::<f64>()
            .sqrt();
        
        // Normaliza pelo erro m√©dio (evita explora√ß√£o de ru√≠do)
        let normalized_error = pred_error / (self.avg_prediction_error + 1e-6);
        
        // Atualiza m√©dia
        self.avg_prediction_error = 0.99 * self.avg_prediction_error + 0.01 * pred_error;
        
        // Recompensa intr√≠nseca
        normalized_error * self.curiosity_scale
    }
    
    /// Treina modelos com experi√™ncia
    pub fn train(&mut self, state: &[f64], action: &[f64], next_state: &[f64]) {
        self.forward_model.train(state, action, next_state);
        self.inverse_model.train(state, next_state, action);
    }
}
```

**Integra√ß√£o com autonomia:** Rede busca ativamente experi√™ncias informativas sem supervis√£o externa.

---

## Parte IV: Melhorias nos Componentes Existentes

### 4.1 Aprimoramento do STDP

**Problema atual:** Janela STDP fixa, n√£o adapta √† estat√≠stica do ambiente.

**Proposta:** STDP com janela adaptativa.

```rust
// Modifica√ß√£o em dendritoma.rs

impl Dendritoma {
    /// STDP com janela adaptativa baseada em reward history
    pub fn apply_adaptive_stdp(&mut self, pre_id: usize, delta_t: i64, reward: f64) {
        // Janela expande com rewards esparsos
        let effective_window = if self.recent_reward_density < 0.1 {
            self.stdp_window * 2  // Dobra janela para capturar cr√©dito distante
        } else {
            self.stdp_window
        };
        
        // Tau adapta √† vari√¢ncia temporal dos rewards
        let effective_tau_plus = self.stdp_tau_plus * (1.0 + self.reward_temporal_variance);
        
        // Aplica STDP com par√¢metros adaptados
        // ...
    }
}
```

### 4.2 Aprimoramento da Homeostase

**Problema atual:** Homeostase pode lutar contra aprendizado √∫til.

**Proposta:** Homeostase context-aware.

```rust
// Modifica√ß√£o em nenv.rs

impl NENV {
    pub fn apply_smart_homeostasis(&mut self, current_time: i64, learning_happening: bool) {
        // Suspende homeostase durante aprendizado ativo
        if learning_happening && self.glia.energy > 50.0 {
            return; // Deixa plasticidade operar
        }
        
        // Homeostase suave, n√£o agressiva
        let rate_error = self.recent_firing_rate - self.target_firing_rate;
        
        // S√≥ interv√©m se erro for grande
        if rate_error.abs() > 0.1 {
            // Ajuste proporcional ao erro
            let adjustment = rate_error.signum() * 0.01 * rate_error.abs().sqrt();
            self.threshold += adjustment;
        }
    }
}
```

### 4.3 Aprimoramento do Sistema de Sono

**Problema atual:** Sono √© baseado em intervalo fixo, n√£o em necessidade.

**Proposta:** Sono orientado por press√£o homeost√°tica.

```rust
// Modifica√ß√£o em network.rs

impl Network {
    /// Press√£o de sono acumula com atividade
    sleep_pressure: f64,
    
    /// Decide autonomamente quando dormir
    pub fn should_sleep(&self) -> bool {
        // Baseado em:
        // 1. Press√£o de sono (adenosina-like)
        // 2. Quantidade de mem√≥rias n√£o consolidadas
        // 3. Estabilidade da rede (baixa novidade)
        
        let unconsolidated = self.count_unconsolidated_memories();
        let novelty_low = self.average_novelty() < 0.05;
        
        self.sleep_pressure > 0.8 && unconsolidated > 10 && novelty_low
    }
    
    /// Acumula press√£o de sono
    pub fn accumulate_sleep_pressure(&mut self) {
        let activity = self.num_firing() as f64 / self.num_neurons() as f64;
        self.sleep_pressure += activity * 0.001;
        self.sleep_pressure = self.sleep_pressure.min(1.0);
    }
    
    /// Reset press√£o ap√≥s sono
    pub fn clear_sleep_pressure(&mut self) {
        self.sleep_pressure *= 0.1; // N√£o zera completamente
    }
}
```

---

## Parte V: Arquitetura Proposta para Intelig√™ncia Ampliada

### 5.1 Diagrama de Componentes Expandido

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         NEN-V v3.0 (Proposta)                          ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                         ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ                    CONTROLE EXECUTIVO                             ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Aten√ß√£o    ‚îÇ  ‚îÇ  Working    ‚îÇ  ‚îÇ  Sele√ß√£o de A√ß√£o       ‚îÇ   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Top-Down   ‚îÇ‚óÑ‚îÄ‚î§  Memory     ‚îÇ‚óÑ‚îÄ‚î§  (Actor-Critic)        ‚îÇ   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ            ‚îÇ                ‚îÇ                     ‚îÇ                     ‚îÇ
‚îÇ            ‚ñº                ‚ñº                     ‚ñº                     ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ                  PROCESSAMENTO TEMPORAL                           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Fast Layer  ‚îÇ  ‚îÇ Medium      ‚îÇ  ‚îÇ  Slow Layer            ‚îÇ   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ (œÑ=10ms)    ‚îÇ‚îÄ‚îÄ‚î§ Layer       ‚îÇ‚îÄ‚îÄ‚î§  (œÑ=200ms)             ‚îÇ   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ             ‚îÇ  ‚îÇ (œÑ=50ms)    ‚îÇ  ‚îÇ  Abstra√ß√£o temporal    ‚îÇ   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                                         ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ                    APRENDIZADO                                    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  STDP       ‚îÇ  ‚îÇ Eligibility ‚îÇ  ‚îÇ  Predi√ß√£o/Modelo       ‚îÇ   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Adaptativo ‚îÇ‚óÑ‚îÄ‚î§ Traces      ‚îÇ‚óÑ‚îÄ‚î§  Interno               ‚îÇ   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ         ‚îÇ                ‚îÇ                     ‚îÇ                 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                          ‚ñº                                       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                              ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ  Neuromodula√ß√£o ‚îÇ                              ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ  Diferencial    ‚îÇ                              ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                              ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                                         ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ                    MEM√ìRIA                                        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Epis√≥dica  ‚îÇ  ‚îÇ Sem√¢ntica   ‚îÇ  ‚îÇ  Procedimental         ‚îÇ   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  (Hippo)    ‚îÇ‚îÄ‚îÄ‚î§ (Cortex)    ‚îÇ‚îÄ‚îÄ‚î§  (Basal Ganglia)       ‚îÇ   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ         ‚îÇ                ‚îÇ                     ‚îÇ                 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                          ‚ñº                                       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                              ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ  Sono/Replay    ‚îÇ                              ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ  Estruturado    ‚îÇ                              ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                              ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                                         ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ                    MOTIVA√á√ÉO                                      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Curiosidade ‚îÇ  ‚îÇ Saciedade/  ‚îÇ  ‚îÇ  Reward Extr√≠nseco     ‚îÇ   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Intr√≠nseca  ‚îÇ‚îÄ‚îÄ‚î§ Necessidade ‚îÇ‚îÄ‚îÄ‚î§  (Ambiente)            ‚îÇ   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 5.2 Prioriza√ß√£o de Implementa√ß√£o

| Prioridade | Componente | Impacto | Complexidade | Autonomia |
|------------|------------|---------|--------------|-----------|
| üî¥ Alta | Working Memory | Cr√≠tico | M√©dia | Alta |
| üî¥ Alta | Predi√ß√£o/Modelo | Cr√≠tico | Alta | Alta |
| üü° M√©dia | Hierarquia Temporal | Alto | M√©dia | Alta |
| üü° M√©dia | Curiosidade Intr√≠nseca | Alto | Baixa | Muito Alta |
| üü° M√©dia | Replay Estruturado | Alto | M√©dia | Alta |
| üü¢ Baixa | Aten√ß√£o Top-Down | M√©dio | M√©dia | M√©dia |
| üü¢ Baixa | Binding Oscilat√≥rio | M√©dio | Alta | Alta |
| üü¢ Baixa | Neuromod. Diferencial | M√©dio | M√©dia | Alta |

---

## Parte VI: M√©tricas de Intelig√™ncia

### 6.1 M√©tricas Propostas para Avalia√ß√£o

```rust
// Novo arquivo: intelligence_metrics.rs

pub struct IntelligenceMetrics {
    /// Capacidade de generaliza√ß√£o
    pub generalization_score: f64,
    
    /// Velocidade de adapta√ß√£o a mudan√ßas
    pub adaptation_speed: f64,
    
    /// Efici√™ncia de cr√©dito temporal
    pub credit_assignment_accuracy: f64,
    
    /// Explora√ß√£o vs Exploitation balance
    pub exploration_efficiency: f64,
    
    /// Capacidade de transfer learning
    pub transfer_score: f64,
    
    /// Robustez a perturba√ß√µes
    pub robustness: f64,
}

impl IntelligenceMetrics {
    /// Avalia generaliza√ß√£o: performance em variantes n√£o vistas
    pub fn measure_generalization(
        network: &Network, 
        training_set: &[Pattern],
        test_set: &[Pattern]
    ) -> f64 {
        let train_accuracy = evaluate_accuracy(network, training_set);
        let test_accuracy = evaluate_accuracy(network, test_set);
        
        // Quanto mais pr√≥ximos, melhor generaliza√ß√£o
        1.0 - (train_accuracy - test_accuracy).abs()
    }
    
    /// Avalia adapta√ß√£o: steps para recuperar performance ap√≥s mudan√ßa
    pub fn measure_adaptation_speed(
        network: &mut Network,
        pre_change_task: &Task,
        post_change_task: &Task
    ) -> f64 {
        // ... implementa√ß√£o
    }
}
```

---

## Parte VII: Considera√ß√µes sobre Autonomia

### 7.1 Princ√≠pios de Design para Autonomia

1. **Minimal Intervention:** O sistema externo s√≥ fornece rewards, nunca for√ßa comportamentos.

2. **Emergent Specialization:** N√£o pr√©-designar fun√ß√µes; deixar especializa√ß√£o emergir.

3. **Self-Regulation:** Todos os par√¢metros adaptativos devem ter loops de feedback internos.

4. **Intrinsic Drives:** Curiosidade e homeostase como motivadores prim√°rios.

5. **No Hidden Supervision:** Evitar t√©cnicas que requerem conhecimento do "correto".

### 7.2 O Que N√ÉO Fazer

| Anti-padr√£o | Por qu√™ evitar |
|-------------|----------------|
| Backpropagation | Requer sinal de erro global n√£o-biol√≥gico |
| Labels expl√≠citos | N√£o dispon√≠veis em ambiente natural |
| Curriculum learning for√ßado | Remove autonomia de explora√ß√£o |
| Regulariza√ß√£o externa | Sistema deve auto-regular |
| Reset de pesos | Rede deve lidar com pr√≥pria estabilidade |

### 7.3 O Que Fazer

| Padr√£o | Justificativa |
|--------|---------------|
| Reward escalar esparso | √önico sinal do ambiente |
| Neuromodula√ß√£o para cr√©dito | Biol√≥gico, local, adaptativo |
| Homeostase multi-escala | Auto-regula√ß√£o emergente |
| Competi√ß√£o por recursos | Sele√ß√£o natural de representa√ß√µes |
| Sono para consolida√ß√£o | Processo aut√¥nomo de organiza√ß√£o |

---

## Parte VIII: Roadmap de Implementa√ß√£o

### Fase 1: Funda√ß√£o (2-3 semanas)
- [ ] Implementar Working Memory b√°sica
- [ ] Adicionar curiosidade intr√≠nseca
- [ ] Expandir m√©tricas de avalia√ß√£o

### Fase 2: Temporal (2-3 semanas)
- [ ] Hierarquia temporal de neur√¥nios
- [ ] Replay epis√≥dico estruturado
- [ ] STDP adaptativo

### Fase 3: Predi√ß√£o (3-4 semanas)
- [ ] Modelo preditivo b√°sico
- [ ] Integra√ß√£o com eligibility traces
- [ ] Sinais de erro de predi√ß√£o

### Fase 4: Integra√ß√£o (2-3 semanas)
- [ ] Aten√ß√£o top-down
- [ ] Neuromodula√ß√£o diferencial
- [ ] Testes de integra√ß√£o

### Fase 5: Refinamento (cont√≠nuo)
- [ ] Ajuste de hiperpar√¢metros
- [ ] Benchmarking em tarefas padr√£o
- [ ] Documenta√ß√£o e exemplos

---

## Conclus√£o

O projeto NEN-V v2.0 representa uma base s√≥lida e biologicamente plaus√≠vel. As lacunas identificadas n√£o s√£o falhas de implementa√ß√£o, mas sim componentes que naturalmente v√™m em fases posteriores de desenvolvimento.

**Pontos fortes atuais:**
- Plasticidade sin√°ptica sofisticada
- Sistema energ√©tico realista
- Homeostase multi-mecanismo
- AutoConfig inteligente

**Prioridades para "intelig√™ncia":**
1. Working Memory (essencial para racioc√≠nio)
2. Modelo Preditivo (essencial para antecipa√ß√£o)
3. Curiosidade Intr√≠nseca (essencial para autonomia)

**Filosofia central:** A rede n√£o deve ser "programada" para ser inteligente; deve ter os **mecanismos corretos** para que intelig√™ncia **emerja** da intera√ß√£o com o ambiente.

---

*Relat√≥rio gerado para an√°lise do projeto NEN-V*  
*Foco: Maximiza√ß√£o de intelig√™ncia com preserva√ß√£o de autonomia*
