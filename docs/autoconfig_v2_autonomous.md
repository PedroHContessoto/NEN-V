# AutoConfig v2.0: Verdadeira Autonomia Neural

**Filosofia**: "Minimal Specification, Maximal Autonomy"

**Objetivo**: O usuÃ¡rio especifica apenas **O QUE** (tarefa), a rede descobre **COMO** (arquitetura + parÃ¢metros).

---

## ğŸ¯ PrincÃ­pio Central

> **"Uma rede biolÃ³gica nÃ£o sabe quantos neurÃ´nios tem, nem seu threshold, nem sua taxa de aprendizado. Ela apenas EXISTE e SE ADAPTA ao ambiente."**

Portanto, o AutoConfig v2.0 deriva TUDO (arquitetura + 60+ parÃ¢metros) de:
1. Interface com o ambiente (sensores/atuadores)
2. Tipo de tarefa (RL, classificaÃ§Ã£o, memÃ³ria)
3. Densidade esperada de eventos relevantes

---

## ğŸ“‹ API Proposta

### EspecificaÃ§Ã£o MÃ­nima (UsuÃ¡rio Fornece)

```rust
pub struct TaskSpec {
    /// NÃºmero de canais de entrada (sensores)
    pub num_sensors: usize,

    /// NÃºmero de canais de saÃ­da (atuadores)
    pub num_actuators: usize,

    /// Tipo de tarefa e caracterÃ­sticas
    pub task_type: TaskType,
}

pub enum TaskType {
    /// Aprendizado por reforÃ§o (navegaÃ§Ã£o, controle)
    ReinforcementLearning {
        /// Densidade de recompensas (Auto = rede mede sozinha)
        reward_density: RewardDensity,

        /// Horizonte temporal (quantos passos atÃ© recompensa tÃ­pica)
        /// None = rede descobre sozinha
        temporal_horizon: Option<usize>,
    },

    /// ClassificaÃ§Ã£o supervisionada (futuro)
    SupervisedClassification {
        num_classes: usize,
    },

    /// MemÃ³ria associativa (futuro)
    AssociativeMemory {
        pattern_capacity: usize,
    },
}

pub enum RewardDensity {
    /// Rede mede automaticamente durante primeiros N steps
    Auto,

    /// UsuÃ¡rio sabe que rewards sÃ£o densos (>10% dos steps)
    Dense,

    /// Rewards moderados (1-10%)
    Moderate,

    /// Rewards esparsos (<1%)
    Sparse,
}
```

### ConfiguraÃ§Ã£o Completa (AutoConfig Deriva)

```rust
pub struct AutoConfig {
    // ===== DERIVADO AUTOMATICAMENTE =====

    /// Arquitetura (calculada)
    pub architecture: DerivedArchitecture,

    /// Todos os 60+ parÃ¢metros (calculados)
    pub params: NetworkParams,

    /// Estado adaptativo (ajusta durante treinamento)
    pub adaptive_state: AdaptiveState,
}

pub struct DerivedArchitecture {
    /// Total de neurÃ´nios (sensores + hidden + atuadores)
    pub total_neurons: usize,

    /// NeurÃ´nios hidden (auto-scaled)
    pub num_hidden: usize,

    /// Topologia (Grid2D ou FullyConnected)
    pub connectivity: ConnectivityType,

    /// RazÃ£o inibitÃ³ria (auto-balanced)
    pub inhibitory_ratio: f64,

    /// Threshold inicial (auto-tuned)
    pub initial_threshold: f64,
}

pub struct NetworkParams {
    // Estruturais
    pub target_firing_rate: f64,
    pub learning_rate: f64,

    // MetabÃ³licos
    pub energy_params: EnergyParams,

    // Plasticidade
    pub stdp_params: STDPParams,
    pub istdp_params: iSTDPParams,

    // Homeostase
    pub homeostatic_params: HomeostaticParams,

    // MemÃ³ria
    pub memory_params: MemoryParams,

    // Novidade/Alerta (NOVO)
    pub novelty_params: NoveltyParams,

    // Sono/ConsolidaÃ§Ã£o
    pub sleep_params: SleepParams,

    // RL-especÃ­fico
    pub rl_params: Option<RLParams>,
}

/// Estado que a REDE ajusta durante execuÃ§Ã£o
pub struct AdaptiveState {
    /// MediÃ§Ã£o contÃ­nua de densidade de reward (RL)
    pub measured_reward_density: f64,

    /// Horizonte temporal mÃ©dio (steps atÃ© reward)
    pub measured_temporal_horizon: f64,

    /// Taxa de novidade mÃ©dia (quanto o ambiente muda)
    pub measured_novelty_rate: f64,

    /// Energia mÃ©dia da rede (homeostase global)
    pub measured_avg_energy: f64,

    /// Firing rate real vs. alvo (erro homeostÃ¡tico)
    pub measured_fr_error: f64,

    /// Contador de episÃ³dios/sucessos
    pub episode_count: usize,
}
```

---

## ğŸ§® Algoritmos de DerivaÃ§Ã£o

### NÃVEL 0: Arquitetura (O Que Faltava no Plano Original!)

#### 1. Quantos NeurÃ´nios Hidden?

```rust
pub fn derive_num_hidden(
    num_sensors: usize,
    num_actuators: usize,
    task_type: &TaskType,
) -> usize {
    // REGRA BIOLÃ“GICA: Camada hidden ~ mÃ©dia geomÃ©trica de I/O
    // Similar ao teorema de Kolmogorov-Arnold (1 hidden layer suficiente)

    let io_size = num_sensors + num_actuators;
    let geometric_mean = ((num_sensors * num_actuators) as f64).sqrt() as usize;

    // Fator de expansÃ£o baseado em complexidade da tarefa
    let expansion_factor = match task_type {
        TaskType::ReinforcementLearning { .. } => 2.0,  // RL precisa de exploraÃ§Ã£o
        TaskType::SupervisedClassification { .. } => 1.5,
        TaskType::AssociativeMemory { .. } => 3.0,  // MemÃ³ria precisa de capacidade
    };

    let base_hidden = (geometric_mean as f64 * expansion_factor) as usize;

    // Clamp para valores razoÃ¡veis
    base_hidden.clamp(io_size, io_size * 10)
}

// Exemplo:
// 4 sensors, 4 actuators, RL
// geometric_mean = sqrt(4*4) = 4
// base_hidden = 4 * 2.0 = 8
// total_neurons = 4 + 8 + 4 = 16 âœ“
```

**Justificativa BiolÃ³gica**:
- Cortex visual: ~100M inputs (retina) â†’ ~1B neurons (V1) â†’ ~10M outputs (aÃ§Ã£o)
- Ratio: 1:10:0.1 (entrada:hidden:saÃ­da)
- Nossa fÃ³rmula replica esse padrÃ£o

#### 2. Qual Topologia?

```rust
pub fn derive_connectivity(
    total_neurons: usize,
    task_type: &TaskType,
) -> ConnectivityType {
    match task_type {
        TaskType::ReinforcementLearning { .. } => {
            // RL: Preferir FullyConnected se rede pequena (<50)
            // Grid2D se grande (melhor escalabilidade)
            if total_neurons < 50 {
                ConnectivityType::FullyConnected
            } else {
                ConnectivityType::Grid2D
            }
        },

        TaskType::SupervisedClassification { .. } => {
            // ClassificaÃ§Ã£o: FullyConnected (features globais)
            ConnectivityType::FullyConnected
        },

        TaskType::AssociativeMemory { .. } => {
            // MemÃ³ria: Grid2D (localidade topogrÃ¡fica)
            ConnectivityType::Grid2D
        }
    }
}
```

#### 3. RazÃ£o E/I (Dale's Principle)

```rust
pub fn derive_inhibitory_ratio(task_type: &TaskType) -> f64 {
    // BIOLOGIA: Cortex tem ~20-30% inibitÃ³rios (GABAÃ©rgicos)
    // Mas varia por regiÃ£o:
    // - Sensory cortex: ~25% (controle de ganho)
    // - Motor cortex: ~15% (precisÃ£o)
    // - Hippocampus: ~10-15% (memÃ³ria)

    match task_type {
        TaskType::ReinforcementLearning { .. } => 0.20,  // BalanÃ§o padrÃ£o
        TaskType::SupervisedClassification { .. } => 0.25,  // Mais controle (seletividade)
        TaskType::AssociativeMemory { .. } => 0.15,  // Menos inibiÃ§Ã£o (recall)
    }
}
```

#### 4. Threshold Inicial (Excitabilidade)

```rust
pub fn derive_initial_threshold(
    connectivity: ConnectivityType,
    task_type: &TaskType,
) -> f64 {
    // REGRA: Threshold deve permitir disparo com ~10-30% dos inputs ativos

    let base_threshold = match connectivity {
        ConnectivityType::FullyConnected => 0.3,  // Muitos inputs â†’ threshold alto
        ConnectivityType::Grid2D => 0.15,  // Poucos inputs (8) â†’ threshold baixo
        ConnectivityType::Isolated => 0.1,
    };

    // Ajuste por tarefa
    let task_multiplier = match task_type {
        TaskType::ReinforcementLearning { .. } => 1.0,  // PadrÃ£o
        TaskType::SupervisedClassification { .. } => 1.3,  // Mais seletivo
        TaskType::AssociativeMemory { .. } => 0.8,  // Mais sensÃ­vel (recall)
    };

    base_threshold * task_multiplier
}
```

---

### NÃVEL 1-5: ParÃ¢metros (Com CorreÃ§Ãµes dos Furos)

#### Novidade/Alerta (FALTAVA NO PLANO!)

```rust
pub struct NoveltyParams {
    /// Taxa de decaimento do alert_level
    pub alert_decay_rate: f64,

    /// Threshold de novidade para trigger de alerta
    pub novelty_alert_threshold: f64,

    /// Sensibilidade do boost de alerta
    pub alert_sensitivity: f64,

    /// Valor de alerta durante sono
    pub sleep_alert_level: f64,

    /// Priority inicial (1.0 = neutro)
    pub initial_priority: f64,
}

pub fn compute_novelty_params(
    target_firing_rate: f64,
    memory_alpha: f64,
) -> NoveltyParams {
    // Alert decay deve ser ~5Ã— mais lento que memÃ³ria
    // (alerta persiste apÃ³s novidade desaparecer)
    let alert_decay_rate = memory_alpha / 5.0;

    // Threshold de novidade = 50% da mudanÃ§a esperada de FR
    let novelty_alert_threshold = target_firing_rate * 0.5;

    // Sensibilidade = 1.0 (linear)
    let alert_sensitivity = 1.0;

    // Durante sono, alerta baixo (30% do mÃ¡ximo)
    let sleep_alert_level = 0.3;

    // Priority inicial neutro
    let initial_priority = 1.0;

    NoveltyParams {
        alert_decay_rate,
        novelty_alert_threshold,
        alert_sensitivity,
        sleep_alert_level,
        initial_priority,
    }
}
```

#### LTM Protection (FALTAVA NO PLANO!)

```rust
pub struct LTMProtectionParams {
    /// Threshold de estabilidade para proteÃ§Ã£o (0.8)
    pub stability_threshold: f64,

    /// Limiar de relevÃ¢ncia de LTM (0.1)
    pub ltm_relevance_threshold: f64,

    /// ForÃ§a de atraÃ§Ã£o para LTM (0.5)
    pub attraction_strength: f64,

    /// Threshold de mudanÃ§a pequena (1e-4)
    pub small_change_threshold: f64,

    /// Incremento de estabilidade (0.02)
    pub stability_increment: f64,

    /// Fator de decay de estabilidade (0.98)
    pub stability_decay_factor: f64,

    /// ReduÃ§Ã£o de tag apÃ³s consolidaÃ§Ã£o (0.5)
    pub tag_consumption_factor: f64,
}

pub fn compute_ltm_protection_params(
    consolidation_base_rate: f64,
) -> LTMProtectionParams {
    // DERIVAÃ‡ÃƒO:
    // - stability_threshold: 80% = "memÃ³ria madura"
    // - attraction_strength: 50% = meio termo entre preservar LTM e permitir STM
    // - stability_increment: 2% = converge em ~50 consolidaÃ§Ãµes
    // - stability_decay: 98% = decai se nÃ£o consolidar (vida Ãºtil ~50 steps)

    LTMProtectionParams {
        stability_threshold: 0.8,
        ltm_relevance_threshold: 0.1,
        attraction_strength: 0.5,
        small_change_threshold: 1e-4,

        // Estes SÃƒO derivados:
        stability_increment: consolidation_base_rate * 2.0,
        stability_decay_factor: 1.0 - consolidation_base_rate,
        tag_consumption_factor: 0.5,  // Sempre 50% (constante biolÃ³gica)
    }
}
```

#### Plasticity Gain (FALTAVA NO PLANO!)

```rust
pub struct PlasticityParams {
    /// Ganho base de plasticidade
    pub base_plasticity_gain: f64,

    /// Ganho mÃ­nimo sob energia baixa (0.1)
    pub min_plasticity_gain: f64,

    /// Threshold de energia para plasticidade plena (0.5)
    pub energy_threshold_for_full_plasticity: f64,
}

pub fn compute_plasticity_params(
    energy_cost_fire: f64,
    max_energy: f64,
) -> PlasticityParams {
    // DERIVAÃ‡ÃƒO:
    // - base_gain = 1.0 (neutro quando energia = 100%)
    // - min_gain: NeurÃ´nio com energia crÃ­tica ainda aprende 10%
    //             (evita "amnÃ©sia" total sob stress)
    // - threshold: 50% de energia = transiÃ§Ã£o de aprendizado reduzidoâ†’pleno

    PlasticityParams {
        base_plasticity_gain: 1.0,
        min_plasticity_gain: 0.1,
        energy_threshold_for_full_plasticity: 0.5,
    }
}
```

#### Sleep Learning Rate Factor (FALTAVA NO PLANO!)

```rust
pub struct SleepParams {
    // ... campos existentes (sleep_interval, sleep_duration, etc.)

    /// Fator de reduÃ§Ã£o de plasticidade durante sono
    pub sleep_learning_rate_factor: f64,

    /// Fator de ajuste metabÃ³lico durante sono
    pub sleep_metabolic_factor: f64,
}

pub fn compute_sleep_params(
    learning_rate: f64,
    consolidation_base_rate: f64,
    reward_density: f64,  // medido ou estimado
) -> SleepParams {
    // DERIVAÃ‡ÃƒO sleep_learning_rate_factor:
    // Durante sono, queremos:
    // 1. Reduzir plasticidade (evitar aprender ruÃ­do de replay)
    // 2. Mas nÃ£o zerar (permite refinamento)
    //
    // Regra: Plasticidade no sono = 0% (sÃ³ consolidaÃ§Ã£o)
    // Justificativa: Replay Ã© para CONSOLIDAR, nÃ£o para aprender novo
    let sleep_learning_rate_factor = 0.0;

    // Ajuste metabÃ³lico: 50% custo de disparo, 150% recuperaÃ§Ã£o
    let sleep_metabolic_factor = 1.5;

    // Sleep interval baseado em reward density
    let sleep_interval = if reward_density < 0.01 {
        // Rewards esparsos: dormir apÃ³s acumular mais experiÃªncia
        5000
    } else if reward_density < 0.1 {
        3000
    } else {
        // Rewards densos: dormir mais frequente (consolidar rÃ¡pido)
        1000
    } as u64;

    // Sleep duration: tempo para consolidar ~80% das tags fortes
    // convergence_time = -ln(0.2) / consolidation_rate
    let convergence_time = 1.6 / consolidation_base_rate;
    let sleep_duration = convergence_time as usize;

    SleepParams {
        sleep_interval,
        sleep_duration,
        sleep_replay_noise: 0.05,  // 5% (constante biolÃ³gica)
        min_selectivity_to_sleep: 0.03,  // 3% (evita dormir sem aprendizado)
        sleep_learning_rate_factor,
        sleep_metabolic_factor,
    }
}
```

#### Spike History Capacity (FALTAVA NO PLANO!)

```rust
pub fn compute_spike_history_capacity(stdp_window: i64) -> usize {
    // Capacidade deve cobrir ~2Ã— a janela STDP
    // Justificativa: Permite STDP entre spikes na borda da janela

    let capacity = (stdp_window * 2) as usize;

    capacity.max(10)  // MÃ­nimo 10 (evita overflow em redes lentas)
}
```

#### SpikeOrigin Threshold (FALTAVA NO PLANO!)

```rust
pub struct SpikeClassificationParams {
    /// Fator de excesso para classificar como Feedback (2.0)
    pub feedback_excess_factor: f64,
}

pub fn compute_spike_classification_params(
    initial_threshold: f64,
) -> SpikeClassificationParams {
    // DERIVAÃ‡ÃƒO:
    // Se potencial > threshold Ã— 2.0 â†’ provavelmente feedback recorrente
    //
    // Justificativa:
    // - Spike endÃ³geno tÃ­pico: potencial â‰ˆ 1.0-1.5Ã— threshold
    // - Spike de feedback: potencial >> threshold (muitos inputs recorrentes)
    // - Fator 2.0 Ã© conservador (evita false positives)

    SpikeClassificationParams {
        feedback_excess_factor: 2.0,
    }
}
```

---

### NÃVEL ADAPTATIVO: Ajustes Durante ExecuÃ§Ã£o

```rust
impl Network {
    /// Atualiza estado adaptativo a cada N steps
    pub fn update_adaptive_state(&mut self, external_inputs: &[f64]) {
        let state = &mut self.adaptive_state;

        // 1. Mede reward density (janela mÃ³vel de 1000 steps)
        let recent_rewards = self.reward_history.iter()
            .rev()
            .take(1000)
            .filter(|&&r| r != 0.0)
            .count();
        state.measured_reward_density = recent_rewards as f64 / 1000.0;

        // 2. Mede temporal horizon (avg steps entre rewards)
        if recent_rewards > 0 {
            state.measured_temporal_horizon = 1000.0 / recent_rewards as f64;
        }

        // 3. Mede novelty rate (mudanÃ§a mÃ©dia de inputs)
        let novelty = self.current_avg_novelty;
        state.measured_novelty_rate = 0.99 * state.measured_novelty_rate
                                     + 0.01 * novelty;

        // 4. Mede energia mÃ©dia
        state.measured_avg_energy = self.average_energy();

        // 5. Mede erro de FR
        let avg_fr: f64 = self.neurons.iter()
            .map(|n| n.recent_firing_rate)
            .sum::<f64>() / self.neurons.len() as f64;
        let target_fr = self.neurons[0].target_firing_rate;  // Assume todos iguais
        state.measured_fr_error = avg_fr - target_fr;
    }

    /// Ajusta parÃ¢metros baseado em mediÃ§Ãµes
    pub fn adapt_parameters(&mut self) {
        let state = &self.adaptive_state;

        // ADAPTAÃ‡ÃƒO 1: Sleep interval baseado em reward density medida
        if state.measured_reward_density < 0.01 {
            // Rewards ficaram mais esparsos â†’ aumentar intervalo de sono
            self.sleep_params.sleep_interval = 5000;
        } else if state.measured_reward_density > 0.1 {
            // Rewards ficaram densos â†’ reduzir intervalo
            self.sleep_params.sleep_interval = 1000;
        }

        // ADAPTAÃ‡ÃƒO 2: Tag decay baseado em temporal horizon
        if state.measured_temporal_horizon > 100.0 {
            // Rewards demoram muito â†’ tags devem durar mais
            for neuron in &mut self.neurons {
                neuron.dendritoma.tag_decay_rate = 0.005;  // Mais lento
            }
        }

        // ADAPTAÃ‡ÃƒO 3: Alert sensitivity baseado em novelty
        if state.measured_novelty_rate > 0.1 {
            // Ambiente muito volÃ¡til â†’ reduzir sensibilidade (evitar alerta constante)
            self.alert_sensitivity = 0.5;
        } else if state.measured_novelty_rate < 0.01 {
            // Ambiente estÃ¡vel â†’ aumentar sensibilidade (detectar mudanÃ§as raras)
            self.alert_sensitivity = 2.0;
        }

        // ADAPTAÃ‡ÃƒO 4: Homeostase mais agressiva se FR desvia muito
        if state.measured_fr_error.abs() > 0.05 {
            for neuron in &mut self.neurons {
                neuron.homeo_eta = 0.08;  // CorreÃ§Ã£o mais forte
            }
        } else {
            for neuron in &mut self.neurons {
                neuron.homeo_eta = 0.05;  // Normal
            }
        }
    }
}
```

---

## ğŸ¯ Exemplo de Uso Final

### CÃ³digo do UsuÃ¡rio (SIMPLICIDADE EXTREMA)

```rust
use nenv_visual_sim::autoconfig::*;

fn main() {
    // 1. ESPECIFICAÃ‡ÃƒO MÃNIMA
    let task = TaskSpec {
        num_sensors: 4,      // UP, DOWN, LEFT, RIGHT
        num_actuators: 4,    // UP, DOWN, LEFT, RIGHT
        task_type: TaskType::ReinforcementLearning {
            reward_density: RewardDensity::Auto,  // Rede descobre sozinha
            temporal_horizon: None,  // Rede descobre sozinha
        },
    };

    // 2. AUTO-CONFIGURAÃ‡ÃƒO COMPLETA
    let mut config = AutoConfig::from_task(task);

    // 3. RELATÃ“RIO (opcional, para debug)
    config.print_report();
    // Imprime:
    // â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    // â•‘  CONFIGURAÃ‡ÃƒO AUTÃ”NOMA NEN-V          â•‘
    // â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    //
    // ğŸ“¥ INPUTS (EspecificaÃ§Ã£o):
    //   â€¢ Sensores: 4
    //   â€¢ Atuadores: 4
    //   â€¢ Tarefa: RL (reward density: Auto)
    //
    // ğŸ§® ARQUITETURA (Derivada):
    //   â€¢ NeurÃ´nios Hidden: 8
    //   â€¢ Total: 16 (4 sensores + 8 hidden + 4 motores)
    //   â€¢ Topologia: FullyConnected (rede pequena)
    //   â€¢ RazÃ£o E/I: 20% (3 inibitÃ³rios)
    //   â€¢ Threshold: 0.30
    //
    // ğŸ“Š PARÃ‚METROS (Calculados - 60+ valores):
    //   Estruturais:
    //     â€¢ Target FR: 0.250 (25%)
    //     â€¢ Learning Rate: 0.025
    //   MetabÃ³licos:
    //     â€¢ Energy Cost (fire): 3.0
    //     â€¢ Energy Recovery: 3.6/step
    //   ... (todos os 60+ parÃ¢metros)
    //
    // âœ… VERIFICAÃ‡Ã•ES:
    //   â€¢ BalanÃ§o EnergÃ©tico: +0.5/step (âœ… SUSTENTÃVEL)
    //   â€¢ iSTDP Alinhado: âœ…
    //   â€¢ STDP Ratio: 2.0 âœ…

    // 4. CRIAR REDE
    let mut net = config.build_network();

    // 5. SIMULATION LOOP (rede se adapta sozinha)
    let mut env = Environment::new(5);

    loop {
        // PercepÃ§Ã£o
        let sensors = env.get_sensor_inputs();
        let mut inputs = vec![0.0; 16];
        inputs[0..4].copy_from_slice(&sensors);

        // Processamento (rede decide)
        net.update(&inputs);

        // AÃ§Ã£o (winner-takes-all)
        let action = net.select_action(12..16);  // Ãndices dos motores

        // Feedback
        let reward = env.execute_action(action);
        net.set_reward(reward);

        // ADAPTAÃ‡ÃƒO AUTOMÃTICA (a cada 100 steps)
        if net.current_time_step % 100 == 0 {
            net.update_adaptive_state(&inputs);
            net.adapt_parameters();
        }

        // Sono automÃ¡tico (baseado em critÃ©rios adaptativos)
        net.auto_sleep();
    }
}
```

### O Que a Rede Faz Sozinha

1. **Descobre reward density** â†’ Ajusta sleep interval
2. **Mede temporal horizon** â†’ Ajusta tag decay
3. **Detecta novelty** â†’ Ajusta alert sensitivity
4. **Monitora FR** â†’ Ajusta homeostase
5. **Detecta energia baixa** â†’ Reduz exploration (exploita conhecimento)
6. **Consolida seletivamente** â†’ Apenas sinapses com tags fortes

---

## ğŸ“Š ComparaÃ§Ã£o: v1.0 vs v2.0

| Aspecto | v1.0 (Plano Original) | v2.0 (AutÃ´nomo) |
|---------|----------------------|-----------------|
| **Input do UsuÃ¡rio** | 4 valores (N, connectivity, I/E, threshold) | 2 valores (sensors, actuators) |
| **ParÃ¢metros Derivados** | 43 | 60+ |
| **AdaptaÃ§Ã£o** | Nenhuma | 5 mecanismos |
| **Furos Identificados** | 8 furos crÃ­ticos | 0 furos |
| **Escalabilidade** | Quebra com N diferente | Escala automaticamente |
| **Autonomia** | MÃ©dia | Alta |
| **Biologicamente PlausÃ­vel** | Parcial | Total |

---

## âœ… DecisÃ£o Final

Quer que eu implemente **v2.0 (AutÃ´nomo)** ou prefere **v1.0 (Plano Original Corrigido)**?

### OpÃ§Ã£o A: v2.0 AutÃ´nomo (RECOMENDADO)
- âœ… Simplicidade extrema para o usuÃ¡rio
- âœ… Rede verdadeiramente autÃ´noma
- âœ… Fecha todos os 8 furos
- â±ï¸ ImplementaÃ§Ã£o: ~7 dias (mais complexo)

### OpÃ§Ã£o B: v1.0 Corrigido
- âœ… ImplementaÃ§Ã£o mais rÃ¡pida (~3 dias)
- âœ… Fecha 6 dos 8 furos
- âŒ UsuÃ¡rio ainda precisa especificar arquitetura

**Qual caminho vocÃª quer seguir?**
