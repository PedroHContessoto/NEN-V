# Hyperparameter Search - NEN-V Optimization System

Sistema completo de otimizaÃ§Ã£o automÃ¡tica de hiperparÃ¢metros para a rede neural NEN-V, com **avaliaÃ§Ã£o real** usando a rede neural integrada em ambientes de benchmark.

## VisÃ£o Geral

O sistema de busca de hiperparÃ¢metros permite encontrar automaticamente a melhor configuraÃ§Ã£o para a rede neural, otimizando **45+ parÃ¢metros** distribuÃ­dos em 12 categorias diferentes.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    HYPERPARAMETER OPTIMIZATION SYSTEM                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚  Parameter      â”‚    â”‚    Search       â”‚    â”‚   Real          â”‚        â”‚
â”‚  â”‚  Space          â”‚â”€â”€â”€â–¶â”‚    Strategy     â”‚â”€â”€â”€â–¶â”‚   Evaluation    â”‚        â”‚
â”‚  â”‚  (45+ params)   â”‚    â”‚  (Bayesian/etc) â”‚    â”‚   (NEN-V Agent) â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚           â”‚                      â”‚                      â”‚                  â”‚
â”‚           â–¼                      â–¼                      â–¼                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚                    Experiment Orchestrator                       â”‚      â”‚
â”‚  â”‚  â€¢ Runs real NEN-V network in benchmark environments            â”‚      â”‚
â”‚  â”‚  â€¢ Collects: reward, success rate, stability, efficiency        â”‚      â”‚
â”‚  â”‚  â€¢ Early stopping and checkpointing                             â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Quick Start

```bash
# Teste rÃ¡pido (10 trials)
cargo run --release --bin hyperopt -- --quick

# Bayesian Optimization (recomendado)
cargo run --release --bin hyperopt -- --strategy bayesian --trials 100

# Ver todas as opÃ§Ãµes
cargo run --release --bin hyperopt -- --help

# ApÃ³s rodar o hyperopt, aplique os resultados ao AutoConfig
cargo run --release --bin apply_hyperopt
```

### Workflow Completo em 4 Passos

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. HYPEROPT           2. APPLY             3. REVIEW           4. TEST    â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚  cargo run --bin       cargo run --bin      Copie o cÃ³digo      cargo test â”‚
â”‚  hyperopt              apply_hyperopt       para derivation.rs  deep_diag  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Estrutura de Arquivos

```
hyperparameter_search/
â”œâ”€â”€ main.rs                  # CLI principal do hyperopt
â”œâ”€â”€ mod.rs                   # MÃ³dulo e re-exports
â”œâ”€â”€ param_space.rs           # DefiniÃ§Ã£o do espaÃ§o de parÃ¢metros (45+)
â”œâ”€â”€ search.rs                # Algoritmos de busca (4 estratÃ©gias)
â”œâ”€â”€ environments.rs          # Ambientes de benchmark parametrizÃ¡veis
â”œâ”€â”€ evaluation.rs            # Sistema de avaliaÃ§Ã£o com NEN-V real
â”œâ”€â”€ orchestrator.rs          # CoordenaÃ§Ã£o de experimentos
â”œâ”€â”€ apply_hyperopt.rs        # Aplicador de resultados â†’ AutoConfig
â”œâ”€â”€ apply_hyperopt_main.rs   # CLI do apply_hyperopt
â””â”€â”€ README.md                # Este arquivo
```

## Arquitetura do Sistema

### IntegraÃ§Ã£o com NEN-V Real

O sistema usa a rede neural NEN-V **real** para avaliaÃ§Ã£o, nÃ£o simulaÃ§Ãµes sintÃ©ticas:

```rust
// NENVAgent usa componentes reais:
pub struct NENVAgent {
    network: Network,                    // Rede NEN-V com STDP, eligibility traces
    working_memory: WorkingMemoryPool,   // Working memory real
    curiosity: CuriosityModule,          // Curiosidade intrÃ­nseca
}
```

### Ambientes de Benchmark

Seis ambientes calibrados para avaliar diferentes capacidades:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         BENCHMARK ENVIRONMENTS                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  INTERNOS (environments.rs):                                                â”‚
â”‚  â”œâ”€â”€ NavigationEnv       (35%)  Grid world com comida/perigo               â”‚
â”‚  â”œâ”€â”€ PatternMemoryEnv    (25%)  MemorizaÃ§Ã£o de sequÃªncias                  â”‚
â”‚  â”œâ”€â”€ PredictionEnv       (25%)  PrevisÃ£o de sÃ©ries temporais               â”‚
â”‚  â””â”€â”€ AssociationEnv      (15%)  Aprendizado estÃ­mulo-resposta              â”‚
â”‚                                                                             â”‚
â”‚  EXTERNOS (simulations/):                                                   â”‚
â”‚  â”œâ”€â”€ GridWorldSensorimotor (10%)  NavegaÃ§Ã£o direcional com sensores        â”‚
â”‚  â””â”€â”€ RealtimeNavigation    (10%)  Movimento 8-direcional com comida/perigo â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

| Ambiente | Origem | DescriÃ§Ã£o | Testa | Peso |
|----------|--------|-----------|-------|------|
| **NavigationEnv** | interno | Grid world com comida/perigo | Aprendizado espacial, reward seeking | 35% |
| **PatternMemoryEnv** | interno | MemorizaÃ§Ã£o de sequÃªncias | Working memory, recall | 25% |
| **PredictionEnv** | interno | PrevisÃ£o de sÃ©ries temporais | Predictive coding, temporal modeling | 25% |
| **AssociationEnv** | interno | Aprendizado estÃ­mulo-resposta | Credit assignment, associaÃ§Ã£o | 15% |
| **GridWorldSensorimotor** | simulations/ | NavegaÃ§Ã£o com 4 sensores direcionais | Mapeamento sensor-motor | 10% |
| **RealtimeNavigation** | simulations/ | Grid complexo com 8 direÃ§Ãµes | NavegaÃ§Ã£o complexa, evasÃ£o | 10% |

### Adicionando Novos Ambientes

Para adicionar uma simulaÃ§Ã£o da pasta `simulations/` ao hyperopt:

1. Crie um adaptador em `external_environments.rs`:
```rust
pub struct MinhaSimulacaoEnv { ... }

impl Environment for MinhaSimulacaoEnv {
    fn reset(&mut self) -> Vec<f64> { ... }
    fn step(&mut self, action: usize) -> StepResult { ... }
    fn observation_size(&self) -> usize { ... }
    fn action_size(&self) -> usize { ... }
    fn name(&self) -> &str { "MinhaSimulacao" }
    fn params(&self) -> &EnvironmentParams { ... }
}
```

2. Adicione o case em `environments.rs` â†’ `create_with_difficulty()`
3. Registre em `default_suite()` com peso apropriado

### CalibraÃ§Ã£o DinÃ¢mica

Os ambientes usam **calibraÃ§Ã£o dinÃ¢mica** baseada em configuraÃ§Ã£o:

```rust
// Threshold calculado automaticamente:
// threshold = random_baseline + X% * (max_reward - random_baseline)
//
// NavigationEnv:  30% acima do baseline
// PatternMemory:  40% acima do baseline
// PredictionEnv:  20% acima do baseline
// AssociationEnv: 35% acima do baseline
```

Isso garante que:
- Thresholds sÃ£o sempre > baseline aleatÃ³rio
- Dificuldade escala com parÃ¢metros do ambiente
- MÃ©tricas sÃ£o comparÃ¡veis entre configuraÃ§Ãµes

### ParametrizaÃ§Ã£o dos Ambientes

Cada ambiente Ã© totalmente configurÃ¡vel:

```rust
// NavigationConfig
NavigationConfig {
    width: 12, height: 12,
    num_food: 5, num_danger: 3,
    food_reward: 1.0,
    danger_penalty: -0.5,
    movement_cost: -0.01,
    food_respawn: true,
}

// Presets de dificuldade
NavigationConfig::easy()   // Mais comida, menos perigo
NavigationConfig::hard()   // Grid maior, mais obstÃ¡culos

// reward_scale Ã© aplicado em todos os steps
let reward = raw_reward * self.params.reward_scale;
```

### Seeds e Reprodutibilidade

Controle completo de seeds em mÃºltiplos nÃ­veis:

```rust
// NÃ­vel de ambiente
env.set_seed(seed);

// NÃ­vel de episÃ³dio
env.reset_with_seed(episode_seed);

// NÃ­vel de experimento
ExperimentConfig { seed: 42, .. }
```

## OpÃ§Ãµes da CLI

```
USAGE:
    cargo run --release --bin hyperopt -- [OPTIONS]

OPTIONS:
    --strategy <NAME>     EstratÃ©gia de busca: bayesian, random, evolutionary
                         (default: bayesian)

    --trials <N>         NÃºmero mÃ¡ximo de trials (default: 100)

    --population <N>     Tamanho da populaÃ§Ã£o para evolutionary (default: 20)

    --importance <F>     ImportÃ¢ncia mÃ­nima de parÃ¢metros [0.0-1.0]
                         (default: 0.6)

    --output <DIR>       DiretÃ³rio de saÃ­da para resultados
                         (default: experiments/results)

    --seed <N>           Seed para reprodutibilidade (default: 42)

    --patience <N>       Early stopping patience (default: 20)

    --name <NAME>        Nome do experimento (default: hyperopt)

    --quick              Teste rÃ¡pido com 10 trials

    --quiet              Suprime output verboso

    --help               Mostra esta mensagem de ajuda
```

## EstratÃ©gias de Busca

### 1. Bayesian Optimization (Recomendado)

```rust
BayesianSearch::new(seed)
    .with_exploration(2.0)  // kappa para UCB
```

**Quando usar:** Poucos trials (<200), funÃ§Ã£o objetivo suave

### 2. Random Search

```rust
RandomSearch::new(seed)
```

**Quando usar:** Baseline, muitos trials, alta dimensÃ£o

### 3. Evolutionary Search

```rust
EvolutionarySearch::new(seed, population_size)
```

**Quando usar:** ParÃ¢metros discretos, landscape multimodal

### 4. Grid Search

```rust
GridSearch::new(points_per_param)
```

**Quando usar:** Poucos parÃ¢metros (<5), debugging

## MÃ©tricas de AvaliaÃ§Ã£o

### Score Combinado

```rust
MetricWeights {
    reward: 0.35,      // Reward mÃ©dio por episÃ³dio
    success: 0.30,     // Taxa de sucesso (reward > threshold)
    stability: 0.15,   // 1 - coef. variaÃ§Ã£o do reward
    learning: 0.10,    // Slope de melhoria ao longo dos episÃ³dios
    efficiency: 0.10,  // Reward / energia consumida
}
```

### MÃ©tricas por Ambiente

```rust
EnvironmentMetrics {
    avg_reward: f64,
    reward_std: f64,
    success_rate: f64,
    best_reward: f64,
    worst_reward: f64,
    avg_firing_rate: f64,
    avg_energy: f64,
}
```

## EspaÃ§o de ParÃ¢metros

### Categorias Principais

| Categoria | # Params | ImportÃ¢ncia | ParÃ¢metros Chave |
|-----------|----------|-------------|------------------|
| learning | 7 | Alta | `base_learning_rate`, `stdp_a_plus/minus` |
| homeostasis | 6 | Alta | `target_firing_rate`, `homeo_eta` |
| timing | 6 | Alta | `stdp_window`, `eligibility_trace_tau` |
| network | 4 | MÃ©dia | `inhibitory_ratio`, `initial_threshold` |
| working_memory | 3 | MÃ©dia | `capacity`, `recurrent_strength` |
| curiosity | 3 | MÃ©dia | `scale`, `habituation_rate` |
| energy | 4 | Baixa | `cost_fire_ratio`, `recovery_rate` |

### Mapeamento para NENVAgent

```rust
// AgentConfig::from_params() mapeia hiperparÃ¢metros para a rede:
impl AgentConfig {
    pub fn from_params(params: &HashMap<String, ParameterValue>) -> Self {
        // Arquitetura
        config.hidden_neurons = params["architecture.hidden_neurons"];
        config.inhibitory_ratio = params["architecture.inhibitory_ratio"];

        // Aprendizado
        config.learning_rate = params["learning.base_learning_rate"];
        config.stdp_tau_plus = params["stdp.tau_plus"];

        // Working Memory
        config.wm_capacity = params["working_memory.capacity"];

        // etc...
    }
}
```

## Output e Resultados

### Arquivos Gerados

```
experiments/results/
â”œâ”€â”€ <name>_log.csv           # Log trial-by-trial
â”œâ”€â”€ <name>_results.txt       # Resumo final com best config
â””â”€â”€ <name>_checkpoint.json   # Checkpoint para resumir
```

## Aplicando Resultados ao AutoConfig

ApÃ³s executar o hyperopt, use a ferramenta `apply_hyperopt` para transferir os parÃ¢metros otimizados para o sistema AutoConfig:

```bash
# Usa automaticamente o melhor resultado disponÃ­vel
cargo run --release --bin apply_hyperopt

# Ou especifique um arquivo de resultados
cargo run --release --bin apply_hyperopt experiments/results/mega_full_results.txt
```

### Como Funciona

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    HYPEROPT â†’ AUTOCONFIG PIPELINE                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  1. HYPEROPT (Offline)                                                      â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                     â”‚
â”‚     â”‚   Busca nos 45  â”‚ â†’ experiments/results/<name>_results.txt            â”‚
â”‚     â”‚   parÃ¢metros    â”‚                                                     â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                     â”‚
â”‚              â”‚                                                              â”‚
â”‚              â–¼                                                              â”‚
â”‚  2. APPLY_HYPEROPT                                                          â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                     â”‚
â”‚     â”‚  LÃª resultados  â”‚ â†’ Parseia valores otimizados                        â”‚
â”‚     â”‚  Gera cÃ³digo    â”‚ â†’ FunÃ§Ãµes Rust para derivation.rs                   â”‚
â”‚     â”‚  Mostra diff    â”‚ â†’ ComparaÃ§Ã£o antes/depois                           â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                     â”‚
â”‚              â”‚                                                              â”‚
â”‚              â–¼                                                              â”‚
â”‚  3. AUTOCONFIG ATUALIZADO                                                   â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                     â”‚
â”‚     â”‚  derivation.rs  â”‚ â†’ Novos defaults otimizados                         â”‚
â”‚     â”‚  (vocÃª copia)   â”‚                                                     â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                     â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Exemplo de Output

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘           HYPEROPT â†’ AUTOCONFIG PARAMETER MAPPING               â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                  â•‘
â•‘  ğŸ“Š HOMEOSTASIS                                                  â•‘
â•‘    refractory_period: 5 â†’ 2                                      â•‘
â•‘    memory_alpha: 0.02 â†’ 0.0457                                   â•‘
â•‘    homeo_eta: 0.1627 â†’ 0.2314                                    â•‘
â•‘                                                                  â•‘
â•‘  ğŸ“ˆ STDP                                                         â•‘
â•‘    window: 16 â†’ 12                                               â•‘
â•‘    tau_plus: 12.8 â†’ 44.65                                        â•‘
â•‘    tau_minus: 4.8 â†’ 18.11                                        â•‘
â•‘                                                                  â•‘
â•‘  ğŸ’¾ MEMORY                                                       â•‘
â•‘    weight_decay: 0.0001 â†’ 0.00467                                â•‘
â•‘                                                                  â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
CÃ“DIGO GERADO (copie para src/autoconfig/derivation.rs)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

pub fn compute_homeostatic_params(target_firing_rate: f64) -> HomeostaticParams {
    HomeostaticParams {
        refractory_period: 2,
        memory_alpha: 0.0457,
        homeo_eta: 0.2314,
        ...
    }
}
```

### Workflow Completo

```bash
# 1. Execute o hyperopt
cargo run --release --bin hyperopt -- --strategy bayesian --trials 200

# 2. Aplique os resultados (gera cÃ³digo)
cargo run --release --bin apply_hyperopt

# 3. Copie o cÃ³digo gerado para derivation.rs
#    (manualmente, revisando as mudanÃ§as)

# 4. Teste a rede com os novos parÃ¢metros
cargo test
cargo run --release --bin deep_diagnostic
```

### Por que nÃ£o atualiza automaticamente?

A ferramenta **gera cÃ³digo** mas nÃ£o sobrescreve automaticamente porque:

1. **RevisÃ£o humana**: VocÃª pode querer ajustar alguns valores
2. **Preservar contexto**: O `derivation.rs` pode ter lÃ³gica adicional
3. **SeguranÃ§a**: Evita regressÃµes acidentais
4. **Flexibilidade**: Permite combinar resultados de mÃºltiplos experimentos

### ParÃ¢metros Mapeados

A ferramenta mapeia **todos os 45 parÃ¢metros** do hyperopt para as funÃ§Ãµes correspondentes em `derivation.rs`:

| FunÃ§Ã£o em derivation.rs | ParÃ¢metros do Hyperopt |
|-------------------------|------------------------|
| `compute_homeostatic_params` | `homeostasis.*`, `timing.refractory_period` |
| `compute_stdp_params` | `timing.stdp_*`, `learning.stdp_*`, `learning.ltp_ltd_ratio` |
| `compute_memory_params` | `memory.*`, `learning.weight_decay` |
| `compute_energy_params` | `energy.*` |
| `compute_stp_params` | `timing.stp_*`, `stp.use_fraction` |
| `compute_competition_params` | `competition.*` |
| `compute_working_memory_params` | `working_memory.*` |
| `compute_curiosity_params` | `curiosity.*` |
| `compute_eligibility_params` | `timing.eligibility_*`, `learning.trace_*` |

### Exemplo de ExecuÃ§Ã£o

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘          HYPERPARAMETER OPTIMIZATION EXPERIMENT             â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ Experiment: hyperopt                                         â•‘
â•‘ Strategy: BayesianOptimization                               â•‘
â•‘ Parameters: 35                                               â•‘
â•‘ Max Trials: 100                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  â˜… Trial    0 | Score: 0.5665 | NEW BEST! | 523ms
  â˜… Trial    1 | Score: 0.6439 | NEW BEST! | 487ms
    Trial   10 | Score: 0.6201 | Best: 0.6638 | 512ms
  â˜… Trial   15 | Score: 0.6891 | NEW BEST! | 498ms
    ...

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    EXPERIMENT COMPLETE                        â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ Total Trials: 100                                            â•‘
â•‘ Best Score: 0.7234                                           â•‘
â•‘ Duration: 52.3s                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

## Adicionando Novos Ambientes

1. Implemente o trait `Environment` em `environments.rs`:

```rust
pub struct MeuAmbiente {
    config: MeuConfig,
    params: EnvironmentParams,
    // ...
}

impl Environment for MeuAmbiente {
    fn reset(&mut self) -> Vec<f64> { ... }
    fn step(&mut self, action: usize) -> StepResult {
        // Calcule raw_reward
        let raw_reward = ...;

        // IMPORTANTE: Aplique reward_scale
        let reward = raw_reward * self.params.reward_scale;

        StepResult::new(obs, reward, done)
    }
    fn observation_size(&self) -> usize { ... }
    fn action_size(&self) -> usize { ... }
    fn name(&self) -> &str { "MeuAmbiente" }
    fn params(&self) -> &EnvironmentParams { &self.params }
    fn random_baseline(&self) -> f64 {
        // Retorne o reward esperado de um agente aleatÃ³rio
        ...
    }
}
```

2. Adicione ao `EnvironmentRegistry`:

```rust
pub fn create_with_difficulty(&self, name: &str, seed: u64, difficulty: f64)
    -> Option<Box<dyn Environment>>
{
    match name {
        "MeuAmbiente" => Some(Box::new(MeuAmbiente::new(seed))),
        // ...
    }
}
```

3. Configure threshold dinÃ¢mico:

```rust
// No construtor:
let random_baseline = /* cÃ¡lculo do baseline */;
let max_reward = /* reward mÃ¡ximo teÃ³rico */;
let success_threshold = random_baseline + (max_reward - random_baseline) * 0.3;
```

## Testes

```bash
# Todos os testes do mÃ³dulo
cargo test --bin hyperopt

# Testes especÃ­ficos
cargo test --bin hyperopt test_success_thresholds
cargo test --bin hyperopt test_random_baselines_calibration
cargo test --bin hyperopt test_nenv_agent_learning
```

## Notas TÃ©cnicas

### CalibraÃ§Ã£o de Rewards

- `reward_scale` Ã© aplicado em **todos** os `step()` dos ambientes
- Thresholds sÃ£o calculados dinamicamente a partir de `config`
- `random_baseline()` retorna valor empÃ­rico para agente aleatÃ³rio
- Testes verificam que `threshold > baseline` para todos os ambientes

### Performance

- ~500ms por trial com rede real (modo release)
- ~50 episÃ³dios por benchmark Ã— 4 ambientes = ~200 episÃ³dios por trial
- Early stopping reduz tempo total significativamente

---

Parte do projeto **NEN-V v2.0**
